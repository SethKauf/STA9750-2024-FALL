[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My first website!",
    "section": "",
    "text": "Hi all, my name is Seth, I’m in the MS Statistics program at Baruch.\nI have some data science experience having taken a bootcamp in 2021 and having worked in the field since completing it.\nI’m in 3 classes this semester, one of which is making me learn and write a lot of math notation in markdown real fast, \\(\\log\\times\\Pr[D_{train}]=\\prod_{i=1}^n(f_1(x_i)^{y_i} \\times f_0(x_i)^{1-y_i})\\times\\log=\\sum_{i=1}^n\\log(f_1(x_i)^{y_i}\\times f_0(x_i)^{1-y_i})\\) was a fun one. \\(k\\in\\Re\\) looks pretty cool, too.\nAnyways, I really like transit data, my first major project was analyzing and predicting train delays on the NYC Subway. I wrote a short blog about gathering MTA data from their Alerts webpage.\nI also am interested in sports data, for example, I want to do a project on how Shot Attempts affect a game and whether they truly matter (something broadcasters cried to the heavens they did this past NHL Stanley Cup Playoffs).\nMy lukewarm take on modern data science, there’s a lot of hype around AI and rightfully so, but I feel there’s some disconnect between what we call AI and what people think of AI. It seems we’re still pretty far from things like autonomous robots, as cool as Bender might be.\n\n\n\nlinked from GIPHY\n\n\nFeel free to direct message me on Piazza or GitHub if you want to connect.\nLooking forward to a great semester!"
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "This project for STA 9750 has us looking at Federal Transit Administration Data, specifically for 2022.\nWe will try to answer some questions about transit from that year in this file."
  },
  {
    "objectID": "docs/mp01.html",
    "href": "docs/mp01.html",
    "title": "Task 1: Rename column UZA Name to metro_area",
    "section": "",
    "text": "library(tidyverse) library(DT)\nFARES &lt;- readxl::read_xlsx(“2022_fare_revenue.xlsx”) |&gt; select(-State/Parent NTD ID, -Reporter Type, -Reporting Module, -TOS, -Passenger Paid Fares, -Organization Paid Fares) |&gt; filter(Expense Type == “Funds Earned During Period”) |&gt; select(-Expense Type)\nEXPENSES &lt;- readr::read_csv(“2022_expenses.csv”) |&gt; select(NTD ID, Agency, Total, Mode) |&gt; mutate(NTD ID = as.integer(NTD ID)) |&gt; rename(Expenses = Total) |&gt; group_by(NTD ID, Mode) |&gt; summarize(Expenses = sum(Expenses)) |&gt; ungroup()\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(NTD ID, Mode))\nTRIPS &lt;- readxl::read_xlsx(“ridership.xlsx”, sheet=“UPT”) |&gt; filter(Mode/Type of Service Status == “Active”) |&gt; select(-Legacy NTD ID, -Reporter Type, -Mode/Type of Service Status, -UACE CD, -TOS) |&gt; pivot_longer(-c(NTD ID:3 Mode), names_to=“month”, values_to=“UPT”) |&gt; drop_na() |&gt; mutate(month=my(month)) # Parse _m_onth _y_ear date specs\nMILES &lt;- readxl::read_xlsx(“ridership.xlsx”, sheet=“VRM”) |&gt; filter(Mode/Type of Service Status == “Active”) |&gt; select(-Legacy NTD ID, -Reporter Type, -Mode/Type of Service Status, -UACE CD, -TOS) |&gt; pivot_longer(-c(NTD ID:3 Mode), names_to=“month”, values_to=“VRM”) |&gt; drop_na() |&gt; group_by(NTD ID, Agency, UZA Name, Mode, 3 Mode, month) |&gt; summarize(VRM = sum(VRM)) |&gt; ungroup() |&gt; mutate(month=my(month)) # Parse _m_onth _y_ear date specs\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt; mutate(NTD ID = as.integer(NTD ID))\nsample_n(USAGE, 1000) |&gt; mutate(month=as.character(month)) |&gt; # DT::datatable()\nhead(USAGE,n=5)\n\nTask 1: Rename column UZA Name to metro_area\nlibrary(dplyr)\ncolnames(USAGE)\nUSAGE &lt;- USAGE |&gt; rename(“metro_area” = “UZA Name”)\ncolnames(USAGE)\n\n\nTask 2: Find unique Modes, impute with a more understandable value using case-when\nhead(USAGE) USAGE |&gt; distinct(Mode) |&gt; arrange(Mode)\nUSAGE &lt;- USAGE |&gt; mutate(Mode=case_when( Mode == “AR” ~ “Alaska Railroad”, Mode == “CB” ~ “Commuter Bus”, Mode == “CC” ~ “Cable Car”, Mode == “CR” ~ “Commuter Rail”, Mode == “DR” ~ “Demand Response”, Mode == “FB” ~ “Ferryboat”, Mode == “HR” ~ “Heavy Rail”, Mode == “IP” ~ “Inclined Plane”, Mode == “LR” ~ “Light Rail”, Mode == “MB” ~ “Bus”, Mode == “MG” ~ “Monorail and Automated Guideway modes”, Mode == “PB” ~ “Publico”, Mode == “RB” ~ “Bus Rapid Transit”, Mode == “SR” ~ “Streetcar Rail”, Mode == “TB” ~ “Trolleybus”, Mode == “TR” ~ “Aerial Tramways”, Mode == “VP” ~ “Vanpool”, Mode == “YR” ~ “Hybrid Rail”, TRUE ~ “Unknown”)) USAGE\nhead(USAGE) USAGE |&gt; distinct(Mode) |&gt; arrange(Mode)\nUSAGE &lt;- USAGE |&gt; rename( “unlinked_passenger_trips” = “UPT”, “vehicle_revenue_miles” = “VRM”) |&gt; select( -NTD ID, -3 Mode)\nlibrary(DT)\nsample_n(USAGE, 1000) |&gt; mutate(month=as.character(month)) |&gt; DT::datatable()\n\n\nTask 3: Answer specific questions\nhead(USAGE)\n#3.1: Which transit agency had the most total VRM in this sample? # A grouped summarize that takes the first returned item in descending order should get that USAGE |&gt; group_by(Agency) |&gt; summarize(n_vrm = n()) |&gt; arrange(desc(n_vrm)) |&gt; slice_head(n=1)\n\n\nAnswer: New Jersey Transit Corporation with 2,048\n\n\n3.2: Which transit mode had the most total VRM in this sample?\n\n\nSame code as 3.1 but replacing Agency with Mode\nUSAGE |&gt; group_by(Mode) |&gt; summarize(n_vrm = n()) |&gt; arrange(desc(n_vrm)) |&gt; slice_head(n=1)\n\n\nAnswer: Demand Response with 115,701\n\n\n3.3: How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\n#install.packages(“stringr”) library(stringr)\n\n\nFirst checking to ensure that May 2024 is only denoted by 2024-05-01\nUSAGE |&gt; filter(str_detect(month, “2024-05-”)) |&gt; distinct(month) #checks out\n\n\nEnsuring I get the right Agency name\nUSAGE |&gt; filter(str_detect(Agency,“MTA”)) |&gt; distinct(Agency)\n\n\nUnlinked Passenger Trips (UPT) are defined as:\n\n\nThe number of passengers who board public transportation vehicles.\n\n\nPassengers are counted each time they board vehicles\n\n\nno matter how many vehicles they use to travel from their origin\n\n\nto their destination.\nUSAGE |&gt; filter(month == ‘2024-05-01’, Agency == “MTA New York City Transit”, Mode == “Heavy Rail”) |&gt; select(unlinked_passenger_trips) #Answer: 180,458,819 trips\n\n\n3.4: Which Mode of transport had the longest average trip in May 2024?\nUSAGE |&gt; filter(month == ‘2024-05-01’) |&gt; group_by(Mode) |&gt; summarize(trips_avg = mean(unlinked_passenger_trips)) |&gt; arrange(desc(trips_avg)) |&gt; slice_head(n=1)\n\n\nAnswer: Heavy Rail, with 14,836,486 average trips\n\n\nI did this question before 3.4 was marked as unneccesary due to not having the correct feature to run this analysis\n\n\nBut I’ve left it in regardless\n\n\n3.5: How much did NYC Subway ridership fall between April 2019 and April 2020?\nUSAGE |&gt; filter(Agency == “MTA New York City Transit”, Mode == “Heavy Rail”, month &gt;= ‘2019-04-01’, month &lt; ‘2020-05-01’) |&gt; select(unlinked_passenger_trips)\n\n\nLet’s plot the ridership numbers\nlibrary(ggplot2) library(lubridate)\ndates &lt;- seq(ymd(“2019-04-01”), by = “month”, length.out = 13) ridership &lt;- c(USAGE |&gt; filter(month &gt;= ‘2019-04-01’, month &lt; ‘2020-05-01’, Agency == ‘MTA New York City Transit’, Mode == ‘Heavy Rail’))\n\n\nCreate a data frame\ndata &lt;- data.frame(Date = dates, Ridership = ridership)\n\n\ninstall.packages(“scales”)\nlibrary(scales)\n\n\nPlot ridership over time\nggplot(data, aes(x = Date, y = Ridership.unlinked_passenger_trips)) + # Change x and y accordingly geom_line() + geom_point() + labs(title = “NYC Subway Ridership from April 2019 through April 2020”, x = “Date”, y = “Total Trips”) + scale_y_continuous(labels = label_number()) + # Prevent scientific notation theme_minimal() + theme( plot.title = element_text(hjust = 0.5, size = 16, face = “bold”), # Center the title and make it bold axis.title.x = element_text(size = 14), # Change x-axis title size axis.title.y = element_text(size = 14), # Change y-axis title size axis.text = element_text(size = 12), # Change axis text size panel.grid.minor = element_blank() # Remove minor grid lines )\n\n\nTask 4: Find 3 more interesting facts in this data\nhead(USAGE, n=7)\n\n\n4.1: What’s the most miles traveled by agency + mode and how does it compare to the number of trips?\nUSAGE |&gt; group_by(Agency, Mode) |&gt; summarize(total_travel = sum(vehicle_revenue_miles, na.rm = TRUE), .groups=“drop”) |&gt; arrange(desc(total_travel)) |&gt; slice_head(n=3) # NYC Subway leads the way in revenue miles, followed by NJT Bus and LA Bus\nUSAGE |&gt; group_by(Agency, Mode) |&gt; summarize(total_travel = sum(unlinked_passenger_trips, na.rm = TRUE), .groups=“drop”) |&gt; arrange(desc(total_travel)) |&gt; slice_head(n=3) # NYC Subway leads the way here as well, while NJT Bus is overtaken by NYC’s bus system # The distance between the MTA and the next few is quite large\n\n\n4.2 Which Agency manages the most Modes?\nUSAGE |&gt; group_by(Agency) |&gt; summarize(total_modes = n_distinct(Mode)) |&gt; arrange(desc(total_modes)) # Massachusetts Bay Transportation Authority\n\n\n4.3 Which date saw the most usage for the NYC Subway?\nUSAGE |&gt; filter(Agency == ‘MTA New York City Transit’, Mode == ‘Heavy Rail’) |&gt; group_by(month) |&gt; summarize(most_trips = sum(unlinked_passenger_trips, na.rm = TRUE)) |&gt; arrange(desc(most_trips)) |&gt; slice_head(n=1) # 2019-10-01\n\n\nconversely, which had the fewest?\nUSAGE |&gt; filter(Agency == ‘MTA New York City Transit’, Mode == ‘Heavy Rail’) |&gt; group_by(month) |&gt; summarize(most_trips = sum(unlinked_passenger_trips, na.rm = TRUE)) |&gt; arrange((most_trips)) |&gt; slice_head(n=1) # 2020-04-01\n\n\nTask 5: Create a new table with annual total (sum) for UPT and VRM for 2022\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt; mutate(NTD ID = as.integer(NTD ID))\nUSAGE &lt;- USAGE |&gt; mutate(Mode=case_when( Mode == “AR” ~ “Alaska Railroad”, Mode == “CB” ~ “Commuter Bus”, Mode == “CC” ~ “Cable Car”, Mode == “CR” ~ “Commuter Rail”, Mode == “DR” ~ “Demand Response”, Mode == “FB” ~ “Ferryboat”, Mode == “HR” ~ “Heavy Rail”, Mode == “IP” ~ “Inclined Plane”, Mode == “LR” ~ “Light Rail”, Mode == “MB” ~ “Bus”, Mode == “MG” ~ “Monorail and Automated Guideway modes”, Mode == “PB” ~ “Publico”, Mode == “RB” ~ “Bus Rapid Transit”, Mode == “SR” ~ “Streetcar Rail”, Mode == “TB” ~ “Trolleybus”, Mode == “TR” ~ “Aerial Tramways”, Mode == “VP” ~ “Vanpool”, Mode == “YR” ~ “Hybrid Rail”, TRUE ~ “Unknown”))\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt; select(-3 Mode) |&gt; rename(“metro_area” = “UZA Name”) |&gt; filter(year(month)==‘2022’) |&gt; group_by(NTD ID, Agency,metro_area,Mode) |&gt; summarize(UPT = sum(UPT), VRM = sum(VRM)) |&gt; ungroup()\nhead(USAGE_2022_ANNUAL, n=2)\nFINANCIALS &lt;- FINANCIALS |&gt; mutate(Mode=case_when( Mode == “AR” ~ “Alaska Railroad”, Mode == “CB” ~ “Commuter Bus”, Mode == “CC” ~ “Cable Car”, Mode == “CR” ~ “Commuter Rail”, Mode == “DR” ~ “Demand Response”, Mode == “FB” ~ “Ferryboat”, Mode == “HR” ~ “Heavy Rail”, Mode == “IP” ~ “Inclined Plane”, Mode == “LR” ~ “Light Rail”, Mode == “MB” ~ “Bus”, Mode == “MG” ~ “Monorail and Automated Guideway modes”, Mode == “PB” ~ “Publico”, Mode == “RB” ~ “Bus Rapid Transit”, Mode == “SR” ~ “Streetcar Rail”, Mode == “TB” ~ “Trolleybus”, Mode == “TR” ~ “Aerial Tramways”, Mode == “VP” ~ “Vanpool”, Mode == “YR” ~ “Hybrid Rail”, TRUE ~ “Unknown”))\nUSAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, FINANCIALS, join_by(NTD ID, Mode)) |&gt; drop_na()\nUSAGE_AND_FINANCIALS\n\n\nTask 6: Answer the following 6 questions using USAGE_AND_FINANCIALS\n\n\n6.1: Which transit system (agency and mode) had the most UPT in 2022?\nUSAGE_AND_FINANCIALS |&gt; group_by(Agency, Mode) |&gt; summarize(Total_UPT = sum(UPT, na.rm=TRUE), .groups=“drop”) |&gt; arrange(desc(Total_UPT)) |&gt; slice_head(n=1) # MTA New York City Transit – Heavy Rail\n\n\n6.2: Which transit system (agency and mode) had the highest farebox recovery,\n\n\ndefined as the highest ratio of Total Fares to Expenses?\nUSAGE_AND_FINANCIALS |&gt; group_by(Agency,Mode) |&gt; summarize(fbx_rcv = sum(Total Fares, na.rm = TRUE) / sum(Expenses, na.rm = TRUE), .groups=“drop”) |&gt; arrange(desc(fbx_rcv)) |&gt; slice_head(n=1) # Transit Authority of Central Kentucky – Vanpool\n\n\n6.3: Which transit system (agency and mode) had the lowest expenses per UPT?\nUSAGE_AND_FINANCIALS |&gt; filter(UPT &gt;= 1) |&gt; group_by(Agency,Mode) |&gt; summarize(lwst_exp_upt = sum(Expenses, na.rm = TRUE) / sum(UPT, na.rm = TRUE), .groups=“drop”) |&gt; arrange(lwst_exp_upt) |&gt; slice_head(n=1) # North Caroline State University – Bus\n\n\n6.4: Which transit system (agency and mode) had the highest total fares per UPT?\nUSAGE_AND_FINANCIALS |&gt; filter(Total Fares &gt;= 1) |&gt; group_by(Agency,Mode) |&gt; summarize(hghst_fr_upt = sum(UPT, na.rm = TRUE) / sum(Total Fares, na.rm = TRUE), .groups=“drop”) |&gt; # summarize(hghst_fr_upt = sum(UPT, na.rm = TRUE) / sum(Total Fares, na.rm = TRUE), .groups=“drop”) |&gt; arrange(desc(hghst_fr_upt)) |&gt; slice_head(n=1) # Athens-Clarke County Unified Government – Bus\n\n\n6.5: Which transit system (agency and mode) had the lowest expenses per VRM?\nUSAGE_AND_FINANCIALS |&gt; filter(UPT &gt;= 1) |&gt; group_by(Agency,Mode) |&gt; summarize(lwst_exp_vrm = sum(Expenses, na.rm = TRUE) / sum(VRM, na.rm = TRUE), .groups=“drop”) |&gt; arrange(lwst_exp_vrm) |&gt; slice_head(n=1) # New Mexico Department of Transportation – Vanpool\n\n\n6.6: Which transit system (agency and mode) had the highest total fares per VRM?\nUSAGE_AND_FINANCIALS |&gt; filter(Total Fares &gt;= 1) |&gt; group_by(Agency,Mode) |&gt; summarize(hghst_fr_vrm = sum(VRM, na.rm = TRUE) / sum(Total Fares, na.rm = TRUE), .groups=“drop”) |&gt; arrange(desc(hghst_fr_vrm)) |&gt; slice_head(n=1) # Athens-Clarke County Unified Government – Bus"
  },
  {
    "objectID": "mp01.html#task-1-rename-column-uza-name-to-metro_area",
    "href": "mp01.html#task-1-rename-column-uza-name-to-metro_area",
    "title": "Mini Project 1",
    "section": "Task 1: Rename column UZA Name to metro_area",
    "text": "Task 1: Rename column UZA Name to metro_area\n\ncolnames(USAGE)\n\n[1] \"NTD ID\"   \"Agency\"   \"UZA Name\" \"Mode\"     \"3 Mode\"   \"month\"    \"UPT\"     \n[8] \"VRM\"     \n\nUSAGE &lt;- USAGE |&gt; rename(\"metro_area\" = \"UZA Name\")\n\ncolnames(USAGE)\n\n[1] \"NTD ID\"     \"Agency\"     \"metro_area\" \"Mode\"       \"3 Mode\"    \n[6] \"month\"      \"UPT\"        \"VRM\""
  },
  {
    "objectID": "mp01.html#task-2-find-unique-modes-impute-with-a-more-understandable-value-using-case-when",
    "href": "mp01.html#task-2-find-unique-modes-impute-with-a-more-understandable-value-using-case-when",
    "title": "Mini Project 1",
    "section": "Task 2: Find unique Modes, impute with a more understandable value using case-when",
    "text": "Task 2: Find unique Modes, impute with a more understandable value using case-when\n\nhead(USAGE)\n\n# A tibble: 6 × 8\n  `NTD ID` Agency      metro_area        Mode  `3 Mode` month         UPT    VRM\n     &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;    &lt;date&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1        1 King County Seattle--Tacoma,… DR    Bus      2002-01-01 135144 746158\n2        1 King County Seattle--Tacoma,… DR    Bus      2002-02-01 127378 656324\n3        1 King County Seattle--Tacoma,… DR    Bus      2002-03-01 136030 726578\n4        1 King County Seattle--Tacoma,… DR    Bus      2002-04-01 142204 736975\n5        1 King County Seattle--Tacoma,… DR    Bus      2002-05-01 144697 746158\n6        1 King County Seattle--Tacoma,… DR    Bus      2002-06-01 131833 696633\n\nUSAGE |&gt;\n  distinct(Mode) |&gt;\n  arrange(Mode)\n\n# A tibble: 18 × 1\n   Mode \n   &lt;chr&gt;\n 1 AR   \n 2 CB   \n 3 CC   \n 4 CR   \n 5 DR   \n 6 FB   \n 7 HR   \n 8 IP   \n 9 LR   \n10 MB   \n11 MG   \n12 PB   \n13 RB   \n14 SR   \n15 TB   \n16 TR   \n17 VP   \n18 YR   \n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode=case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail and Automated Guideway modes\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramways\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"))\n\nhead(USAGE)\n\n# A tibble: 6 × 8\n  `NTD ID` Agency      metro_area        Mode  `3 Mode` month         UPT    VRM\n     &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;    &lt;date&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1        1 King County Seattle--Tacoma,… Dema… Bus      2002-01-01 135144 746158\n2        1 King County Seattle--Tacoma,… Dema… Bus      2002-02-01 127378 656324\n3        1 King County Seattle--Tacoma,… Dema… Bus      2002-03-01 136030 726578\n4        1 King County Seattle--Tacoma,… Dema… Bus      2002-04-01 142204 736975\n5        1 King County Seattle--Tacoma,… Dema… Bus      2002-05-01 144697 746158\n6        1 King County Seattle--Tacoma,… Dema… Bus      2002-06-01 131833 696633\n\nUSAGE |&gt;\n  distinct(Mode) |&gt;\n  arrange(Mode)\n\n# A tibble: 18 × 1\n   Mode                                 \n   &lt;chr&gt;                                \n 1 Aerial Tramways                      \n 2 Alaska Railroad                      \n 3 Bus                                  \n 4 Bus Rapid Transit                    \n 5 Cable Car                            \n 6 Commuter Bus                         \n 7 Commuter Rail                        \n 8 Demand Response                      \n 9 Ferryboat                            \n10 Heavy Rail                           \n11 Hybrid Rail                          \n12 Inclined Plane                       \n13 Light Rail                           \n14 Monorail and Automated Guideway modes\n15 Publico                              \n16 Streetcar Rail                       \n17 Trolleybus                           \n18 Vanpool                              \n\nUSAGE &lt;- USAGE |&gt;     rename( \"unlinked_passenger_trips\" = \"UPT\",\n                              \"vehicle_revenue_miles\" = \"VRM\") |&gt;\n  select( -`NTD ID`,\n          -`3 Mode`)\n\nsample_n(USAGE, 1000) |&gt; \n    mutate(month=as.character(month)) |&gt; \n    DT::datatable()"
  },
  {
    "objectID": "mp01.html#task-3-answer-specific-questions",
    "href": "mp01.html#task-3-answer-specific-questions",
    "title": "Mini Project 1",
    "section": "Task 3: Answer specific questions",
    "text": "Task 3: Answer specific questions\n\nhead(USAGE)\n\n# A tibble: 6 × 6\n  Agency      metro_area          Mode         month      unlinked_passenger_t…¹\n  &lt;chr&gt;       &lt;chr&gt;               &lt;chr&gt;        &lt;date&gt;                      &lt;dbl&gt;\n1 King County Seattle--Tacoma, WA Demand Resp… 2002-01-01                 135144\n2 King County Seattle--Tacoma, WA Demand Resp… 2002-02-01                 127378\n3 King County Seattle--Tacoma, WA Demand Resp… 2002-03-01                 136030\n4 King County Seattle--Tacoma, WA Demand Resp… 2002-04-01                 142204\n5 King County Seattle--Tacoma, WA Demand Resp… 2002-05-01                 144697\n6 King County Seattle--Tacoma, WA Demand Resp… 2002-06-01                 131833\n# ℹ abbreviated name: ¹​unlinked_passenger_trips\n# ℹ 1 more variable: vehicle_revenue_miles &lt;dbl&gt;\n\n\n\n3.1: Which transit agency had the most total VRM in this sample?\n\n# A grouped summarize that takes the first returned item in descending order should get that\nUSAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(n_vrm = n()) |&gt;\n  arrange(desc(n_vrm)) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 2\n  Agency                         n_vrm\n  &lt;chr&gt;                          &lt;int&gt;\n1 New Jersey Transit Corporation  2048\n\n\nAnswer: New Jersey Transit Corporation with 2,048\n\n\n3.2: Which transit mode had the most total VRM in this sample?\n\n# Same code as 3.1 but replacing Agency with Mode\nUSAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(n_vrm = n()) |&gt;\n  arrange(desc(n_vrm)) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 2\n  Mode             n_vrm\n  &lt;chr&gt;            &lt;int&gt;\n1 Demand Response 115701\n\n\nAnswer: Demand Response with 115,701\n\n\n3.3: How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\n\n#install.packages(\"stringr\")\nlibrary(stringr)\n\n# First checking to ensure that May 2024 is only denoted by 2024-05-01\nUSAGE |&gt;\n  filter(str_detect(month, \"2024-05-\")) |&gt;\n  distinct(month) #checks out\n\n# A tibble: 1 × 1\n  month     \n  &lt;date&gt;    \n1 2024-05-01\n\n# Ensuring I get the right Agency name\nUSAGE |&gt;\n  filter(str_detect(Agency,\"MTA\")) |&gt;\n  distinct(Agency)\n\n# A tibble: 4 × 1\n  Agency                                                              \n  &lt;chr&gt;                                                               \n1 MTA New York City Transit                                           \n2 Metro-North Commuter Railroad Company, dba: MTA Metro-North Railroad\n3 MTA Long Island Rail Road                                           \n4 MTA Bus Company                                                     \n\n# Unlinked Passenger Trips (UPT) are defined as:\n# The number of passengers who board public transportation vehicles.\n# Passengers are counted each time they board vehicles\n# no matter how many vehicles they use to travel from their origin\n# to their destination.\n\n\nUSAGE |&gt;\n  filter(month == '2024-05-01',\n         Agency == \"MTA New York City Transit\",\n         Mode == \"Heavy Rail\") |&gt;\n  select(unlinked_passenger_trips)\n\n# A tibble: 1 × 1\n  unlinked_passenger_trips\n                     &lt;dbl&gt;\n1                180458819\n\n\nAnswer: 180,458,819 trips\n\n\n3.4: Which Mode of transport had the longest average trip in May 2024?\n\nUSAGE |&gt;\n  filter(month == '2024-05-01') |&gt;\n  group_by(Mode) |&gt;\n  summarize(trips_avg = mean(unlinked_passenger_trips)) |&gt;\n  arrange(desc(trips_avg)) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 2\n  Mode       trips_avg\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Heavy Rail 14836486.\n\n\nAnswer: Heavy Rail, with 14,836,486 average trips (I did this question before 3.4 was marked as unneccesary due to not having the correct feature to run this analysis, but I’ve left it in regardless)\n\n\n3.5: How much did NYC Subway ridership fall between April 2019 and April 2020?\n\nUSAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\",\n         Mode == \"Heavy Rail\",\n         month &gt;= '2019-04-01',\n         month &lt; '2020-05-01') |&gt;\n  select(unlinked_passenger_trips)\n\n# A tibble: 13 × 1\n   unlinked_passenger_trips\n                      &lt;dbl&gt;\n 1                232223929\n 2                235967209\n 3                224274463\n 4                229774505\n 5                229171856\n 6                230694038\n 7                253609943\n 8                235137305\n 9                236357677\n10                231863427\n11                227432375\n12                119654860\n13                 20254269\n\n# Let's plot the ridership numbers\nif(!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\n\nlibrary(ggplot2)\nlibrary(lubridate)\n\ndates &lt;- seq(ymd(\"2019-04-01\"), by = \"month\", length.out = 13)\n\nridership &lt;- c(USAGE |&gt;\n                 filter(month &gt;= '2019-04-01',\n                        month &lt; '2020-05-01',\n                        Agency == 'MTA New York City Transit',\n                        Mode == 'Heavy Rail'))\n\n# Create a data frame\ndata &lt;- data.frame(Date = dates, Ridership = ridership)\n\nif(!require(\"scales\")) install.packages(\"scales\")\n\nLoading required package: scales\n\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(scales)\n\n# Plot ridership over time\nggplot(data, aes(x = Date, y = Ridership.unlinked_passenger_trips)) +  # Change x and y accordingly\n  geom_line() +\n  geom_point() +\n  labs(title = \"NYC Subway Ridership from April 2019 through April 2020\", x = \"Date\", y = \"Total Trips\") +\n  scale_y_continuous(labels = label_number()) +  # Prevent scientific notation\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),  # Center the title and make it bold\n    axis.title.x = element_text(size = 14),  # Change x-axis title size\n    axis.title.y = element_text(size = 14),  # Change y-axis title size\n    axis.text = element_text(size = 12),  # Change axis text size\n    panel.grid.minor = element_blank()  # Remove minor grid lines\n  )"
  },
  {
    "objectID": "mp01.html#task-4-find-3-more-interesting-facts-in-this-data",
    "href": "mp01.html#task-4-find-3-more-interesting-facts-in-this-data",
    "title": "Mini Project 1",
    "section": "Task 4: Find 3 more interesting facts in this data",
    "text": "Task 4: Find 3 more interesting facts in this data\n\nhead(USAGE, n=7)\n\n# A tibble: 7 × 6\n  Agency      metro_area          Mode         month      unlinked_passenger_t…¹\n  &lt;chr&gt;       &lt;chr&gt;               &lt;chr&gt;        &lt;date&gt;                      &lt;dbl&gt;\n1 King County Seattle--Tacoma, WA Demand Resp… 2002-01-01                 135144\n2 King County Seattle--Tacoma, WA Demand Resp… 2002-02-01                 127378\n3 King County Seattle--Tacoma, WA Demand Resp… 2002-03-01                 136030\n4 King County Seattle--Tacoma, WA Demand Resp… 2002-04-01                 142204\n5 King County Seattle--Tacoma, WA Demand Resp… 2002-05-01                 144697\n6 King County Seattle--Tacoma, WA Demand Resp… 2002-06-01                 131833\n7 King County Seattle--Tacoma, WA Demand Resp… 2002-07-01                 137547\n# ℹ abbreviated name: ¹​unlinked_passenger_trips\n# ℹ 1 more variable: vehicle_revenue_miles &lt;dbl&gt;\n\n\n\n4.1: What’s the most miles traveled by agency + mode and how does it compare to the number of trips?\n\nUSAGE |&gt;\n  group_by(Agency, Mode) |&gt;\n  summarize(total_travel = sum(vehicle_revenue_miles, na.rm = TRUE), .groups=\"drop\") |&gt;\n  arrange(desc(total_travel)) |&gt;\n  slice_head(n=3)\n\n# A tibble: 3 × 3\n  Agency                                                   Mode     total_travel\n  &lt;chr&gt;                                                    &lt;chr&gt;           &lt;dbl&gt;\n1 MTA New York City Transit                                Heavy R…   7732916753\n2 New Jersey Transit Corporation                           Bus        3781858802\n3 Los Angeles County Metropolitan Transportation Authority Bus        3501202902\n\n\nNYC Subway leads the way in revenue miles, followed by NJT Bus and LA Bus\n\nUSAGE |&gt;\n  group_by(Agency, Mode) |&gt;\n  summarize(total_travel = sum(unlinked_passenger_trips, na.rm = TRUE), .groups=\"drop\") |&gt;\n  arrange(desc(total_travel)) |&gt;\n  slice_head(n=3)\n\n# A tibble: 3 × 3\n  Agency                                                   Mode     total_travel\n  &lt;chr&gt;                                                    &lt;chr&gt;           &lt;dbl&gt;\n1 MTA New York City Transit                                Heavy R…  51672094135\n2 MTA New York City Transit                                Bus       16889723939\n3 Los Angeles County Metropolitan Transportation Authority Bus        7114375207\n\n\nNYC Subway leads the way here as well, while NJT Bus is overtaken by NYC’s bus system. The distance between the MTA and the next few is quite large.\n\n\n4.2 Which Agency manages the most Modes?\n\nUSAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(total_modes = n_distinct(Mode)) |&gt;\n  arrange(desc(total_modes)) # Massachusetts Bay Transportation Authority\n\n# A tibble: 677 × 2\n   Agency                                                   total_modes\n   &lt;chr&gt;                                                          &lt;int&gt;\n 1 Massachusetts Bay Transportation Authority                         7\n 2 Central Oklahoma Transportation and Parking Authority              6\n 3 City and County of San Francisco                                   6\n 4 City of Charlotte North Carolina                                   6\n 5 County of Miami-Dade                                               6\n 6 Dallas Area Rapid Transit                                          6\n 7 King County                                                        6\n 8 Los Angeles County Metropolitan Transportation Authority           6\n 9 Maryland Transit Administration                                    6\n10 Metropolitan Transit Authority of Harris County, Texas             6\n# ℹ 667 more rows\n\n\n\n\n4.3 Which date saw the most usage for the NYC Subway?\n\nUSAGE |&gt;\n  filter(Agency == 'MTA New York City Transit',\n         Mode == 'Heavy Rail') |&gt;\n  group_by(month) |&gt;\n  summarize(most_trips = sum(unlinked_passenger_trips, na.rm = TRUE)) |&gt;\n  arrange(desc(most_trips)) |&gt;\n  slice_head(n=1) # 2019-10-01\n\n# A tibble: 1 × 2\n  month      most_trips\n  &lt;date&gt;          &lt;dbl&gt;\n1 2019-10-01  253609943\n\n# conversely, which had the fewest?\nUSAGE |&gt;\n  filter(Agency == 'MTA New York City Transit',\n         Mode == 'Heavy Rail') |&gt;\n  group_by(month) |&gt;\n  summarize(most_trips = sum(unlinked_passenger_trips, na.rm = TRUE)) |&gt;\n  arrange((most_trips)) |&gt;\n  slice_head(n=1) # 2020-04-01\n\n# A tibble: 1 × 2\n  month      most_trips\n  &lt;date&gt;          &lt;dbl&gt;\n1 2020-04-01   20254269\n\n\n2019-10-01 had the most while 2020-04-01 had the fewest"
  },
  {
    "objectID": "mp01.html#task-5-create-a-new-table-with-annual-total-sum-for-upt-and-vrm-for-2022",
    "href": "mp01.html#task-5-create-a-new-table-with-annual-total-sum-for-upt-and-vrm-for-2022",
    "title": "Mini Project 1",
    "section": "Task 5: Create a new table with annual total (sum) for UPT and VRM for 2022",
    "text": "Task 5: Create a new table with annual total (sum) for UPT and VRM for 2022\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nJoining with `by = join_by(`NTD ID`, Agency, `UZA Name`, Mode, `3 Mode`,\nmonth)`\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode=case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail and Automated Guideway modes\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramways\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"))\n\n\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt;\n  select(-`3 Mode`) |&gt;\n  rename(\"metro_area\" = \"UZA Name\") |&gt;\n  filter(year(month)=='2022') |&gt;\n  group_by(`NTD ID`, `Agency`,`metro_area`,`Mode`) |&gt;\n  summarize(UPT = sum(UPT),\n            VRM = sum(VRM)) |&gt;\n  ungroup()\n\n`summarise()` has grouped output by 'NTD ID', 'Agency', 'metro_area'. You can\noverride using the `.groups` argument.\n\nhead(USAGE_2022_ANNUAL, n=2)\n\n# A tibble: 2 × 6\n  `NTD ID` Agency      metro_area          Mode                 UPT      VRM\n     &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;               &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;\n1        1 King County Seattle--Tacoma, WA Bus             53983641 61632644\n2        1 King County Seattle--Tacoma, WA Demand Response   663009 12860448\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(Mode=case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail and Automated Guideway modes\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramways\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"))\n\n\nUSAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL,\n                                  FINANCIALS,\n                                  join_by(`NTD ID`, `Mode`)) |&gt;\n  drop_na()\n\n\nhead(USAGE_AND_FINANCIALS,n=7)\n\n# A tibble: 7 × 9\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1        1 King Coun… Seattle--… Bus   5.40e7 6.16e7 King County …      56566150\n2        1 King Coun… Seattle--… Bus   5.40e7 6.16e7 King County …        280187\n3        1 King Coun… Seattle--… Dema… 6.63e5 1.29e7 King County …        740726\n4        1 King Coun… Seattle--… Dema… 6.63e5 1.29e7 King County …         91601\n5        1 King Coun… Seattle--… Ferr… 4.00e5 5.12e4 King County …       1715265\n6        1 King Coun… Seattle--… Stre… 1.12e6 1.80e5 King County …        588495\n7        1 King Coun… Seattle--… Trol… 9.58e6 2.64e6 King County …      10123486\n# ℹ 1 more variable: Expenses &lt;dbl&gt;"
  },
  {
    "objectID": "mp01.html#task-6-answer-the-following-6-questions-using-usage_and_financials",
    "href": "mp01.html#task-6-answer-the-following-6-questions-using-usage_and_financials",
    "title": "Mini Project 1",
    "section": "Task 6: Answer the following 6 questions using USAGE_AND_FINANCIALS",
    "text": "Task 6: Answer the following 6 questions using USAGE_AND_FINANCIALS\n\n6.1: Which transit system (agency and mode) had the most UPT in 2022?\n\nUSAGE_AND_FINANCIALS |&gt;\n  group_by(`Agency`, `Mode`) |&gt;\n  summarize(Total_UPT = sum(UPT, na.rm=TRUE), .groups=\"drop\") |&gt;\n  arrange(desc(Total_UPT)) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 3\n  Agency                    Mode        Total_UPT\n  &lt;chr&gt;                     &lt;chr&gt;           &lt;dbl&gt;\n1 MTA New York City Transit Heavy Rail 1793073801\n\n\nMTA New York City Transit – Heavy Rail\n\n\n6.2: Which transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\n\nUSAGE_AND_FINANCIALS |&gt;\n  group_by(`Agency`,`Mode`) |&gt;\n  summarize(fbx_rcv = sum(`Total Fares`, na.rm = TRUE) / sum(`Expenses`, na.rm = TRUE), .groups=\"drop\") |&gt;\n  arrange(desc(fbx_rcv)) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 3\n  Agency                                Mode    fbx_rcv\n  &lt;chr&gt;                                 &lt;chr&gt;     &lt;dbl&gt;\n1 Transit Authority of Central Kentucky Vanpool    2.38\n\n\nTransit Authority of Central Kentucky – Vanpool\n\n\n6.3: Which transit system (agency and mode) had the lowest expenses per UPT?\n\nUSAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 1) |&gt;\n  group_by(`Agency`,`Mode`) |&gt;\n  summarize(lwst_exp_upt =  sum(`Expenses`, na.rm = TRUE) / sum(`UPT`, na.rm = TRUE), .groups=\"drop\") |&gt;\n  arrange(lwst_exp_upt) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 3\n  Agency                          Mode  lwst_exp_upt\n  &lt;chr&gt;                           &lt;chr&gt;        &lt;dbl&gt;\n1 North Carolina State University Bus           1.18\n\n\nNorth Caroline State University – Bus\n\n\n6.4: Which transit system (agency and mode) had the highest total fares per UPT?\n\nUSAGE_AND_FINANCIALS |&gt;\n  filter(`Total Fares` &gt;= 1) |&gt;\n  group_by(`Agency`,`Mode`) |&gt;\n  summarize(hghst_fr_upt = sum(`UPT`, na.rm = TRUE) / sum(`Total Fares`, na.rm = TRUE), .groups=\"drop\") |&gt;\n  # summarize(hghst_fr_upt = sum(`UPT`, na.rm = TRUE) / sum(`Total Fares`, na.rm = TRUE), .groups=\"drop\")  |&gt;\n  arrange(desc(hghst_fr_upt)) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 3\n  Agency                                  Mode  hghst_fr_upt\n  &lt;chr&gt;                                   &lt;chr&gt;        &lt;dbl&gt;\n1 Athens-Clarke County Unified Government Bus         522940\n\n\nAthens-Clarke County Unified Government – Bus\n\n\n6.5: Which transit system (agency and mode) had the lowest expenses per VRM?\n\nUSAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 1) |&gt;\n  group_by(`Agency`,`Mode`) |&gt;\n  summarize(lwst_exp_vrm = sum(`Expenses`, na.rm = TRUE) / sum(`VRM`, na.rm = TRUE), .groups=\"drop\") |&gt;\n  arrange(lwst_exp_vrm) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 3\n  Agency                                  Mode    lwst_exp_vrm\n  &lt;chr&gt;                                   &lt;chr&gt;          &lt;dbl&gt;\n1 New Mexico Department of Transportation Vanpool        0.337\n\n\nNew Mexico Department of Transportation – Vanpool\n\n\n6.6: Which transit system (agency and mode) had the highest total fares per VRM?\n\nUSAGE_AND_FINANCIALS |&gt;\n  filter(`Total Fares` &gt;= 1) |&gt;\n  group_by(`Agency`,`Mode`) |&gt;\n  summarize(hghst_fr_vrm = sum(`VRM`, na.rm = TRUE) / sum(`Total Fares`, na.rm = TRUE), .groups=\"drop\") |&gt;\n  arrange(desc(hghst_fr_vrm)) |&gt;\n  slice_head(n=1)\n\n# A tibble: 1 × 3\n  Agency                                  Mode  hghst_fr_vrm\n  &lt;chr&gt;                                   &lt;chr&gt;        &lt;dbl&gt;\n1 Athens-Clarke County Unified Government Bus         380687\n\n\nAthens-Clarke County Unified Government – Bus"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "Introduction\nFor STA 9750 Mini Project 2, I’m going to propose remaking a classic movie: Independence Day.\n\n\n\nWatch out, Earth!\n\n\n\n\nTask 7: Pitch\nOriginally released in 1996 and starring Will Smith, this film depicts Earth’s fight for freedom from an alien invasion.\nStarring Jacob Batalon in his breakout role as Captain Steven Hiller and famous robo-freedom-fighter John DiMaggio as David Levinson, this film follows an ensemble of characters as they look to save Earth from the new threat from the aliens of Omicron Persei 10.\n\n\n\n\nJacob Batalon\n\n\n\n\n\nJohn DiMaggio\n\n\n\nDirected by Glass Onion and Knives Out director Rian Johnson, the action behind this film belies the mystery of the Omicronians and their true plot.\n\n\n\nRian Johnson\n\n\n# How we got here Now that I’ve thoroughly grabbed your attention, how the heck did we come up with this cast of characters?\nAfter sorting through IMDb data, these three just truly spoke to us and we knew we were on to something.\n\n\nTask 0: In which the data is gathered\nSince we’re doing this in R, let’s get some code going\n\n# Install and import packages\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"glue\")) install.packages(\"glue\")\nif (!require(\"scales\")) install.packages(\"scales\")\nif (!require(\"psych\")) install.packages(\"psych\")\nif (!require(\"plotly\")) install.packages(\"plotly\")\nif (!require(\"readr\")) install.packages(\"readr\")\nif (!require(\"DT\")) install.packages(\"DT\")\nif (!require(\"ggrepel\")) install.packages(\"ggrepel\")\n\nlibrary(DT)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(glue)\nlibrary(scales)\nlibrary(psych)\nlibrary(plotly)\nlibrary(readr)\nlibrary(ggrepel)\n\nNext let’s import our data\n\nget_imdb_file &lt;- function(fname) {\n  BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n  fname_ext &lt;- paste0(fname, \".tsv.gz\")\n  if (!file.exists(fname_ext)) {\n    FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n    download.file(FILE_URL,\n                  destfile = fname_ext\n    )\n  }\n  as.data.frame(readr::read_tsv(fname_ext, lazy = FALSE))\n}\n\nNAME_BASICS &lt;- get_imdb_file(\"name.basics\")\n\nTITLE_BASICS &lt;- get_imdb_file(\"title.basics\")\n\nTITLE_EPISODES &lt;- get_imdb_file(\"title.episode\")\n\nTITLE_RATINGS &lt;- get_imdb_file(\"title.ratings\")\n\nTITLE_CREW &lt;- get_imdb_file(\"title.crew\")\n\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n  filter(str_count(knownForTitles, \",\") &gt; 1)\n\nLooking at the data we just pulled\n\nTITLE_RATINGS |&gt;\n  ggplot(aes(x = numVotes)) +\n  geom_histogram(bins = 30) +\n  xlab(\"Number of IMDB Ratings\") +\n  ylab(\"Number of Titles\") +\n  ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") +\n  theme_bw() +\n  scale_x_log10(label = scales::comma) +\n  scale_y_continuous(label = scales::comma)\n\n\n\n\n\n\n\n\n\nTITLE_RATINGS |&gt;\n  pull(numVotes) |&gt;\n  quantile()\n\n     0%     25%     50%     75%    100% \n      5      11      26     101 2952383 \n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  filter(numVotes &gt;= 100)\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n  semi_join(\n    TITLE_RATINGS,\n    join_by(tconst == tconst)\n  )\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n  semi_join(\n    TITLE_RATINGS,\n    join_by(tconst == tconst)\n  )\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n  semi_join(\n    TITLE_RATINGS,\n    join_by(tconst == tconst)\n  )\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n  semi_join(\n    TITLE_RATINGS,\n    join_by(parentTconst == tconst)\n  )\n\nTITLE_EPISODES &lt;- bind_rows(\n  TITLE_EPISODES_1,\n  TITLE_EPISODES_2\n) |&gt;\n  distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n  semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n# EDA\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n  mutate(\n    birthYear = as.numeric(birthYear),\n    deathYear = as.numeric(deathYear)\n  )\n\nWe have several tasks to complete with this data, including some EDA!\n\n\nTask 1: Clean Clean Clean\n\nconvert_columns &lt;- function(data, columns, conversion = \"numeric\") {\n  # Check if conversion is valid\n  \n  if (!conversion %in% c(\"numeric\", \"logical\")) {\n    stop(\"Invalid conversion type. Choose either 'numeric' or 'logical'.\")\n  }\n  \n  # Apply the conversion based on argument\n  if (conversion == \"numeric\") {\n    data &lt;- data |&gt;\n      mutate(across(all_of(columns), as.numeric))\n  } else if (conversion == \"logical\") {\n    data &lt;- data |&gt;\n      mutate(across(all_of(columns), as.logical))\n  }\n  \n  return(data)\n}\n\nTITLE_BASICS &lt;- convert_columns(TITLE_BASICS, columns = c(\"startYear\", \"endYear\", \"runtimeMinutes\"), conversion = \"numeric\")\n\nTITLE_EPISODES &lt;- convert_columns(TITLE_EPISODES, columns = c(\"seasonNumber\", \"episodeNumber\"), conversion = \"numeric\")\n\n\n\nTask 2: Provided Questions, Provided Answers\nHere we seek to answer several questions from the dataset.\n\n# 2.1: How many movies are in our data set? How many TV series? How many TV episodes?\n\n# TITLE_BASICS will have this answer\nglimpse(TITLE_BASICS)\n\nRows: 374,231\nColumns: 9\n$ tconst         &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt…\n$ titleType      &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"…\n$ primaryTitle   &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Poor Pierrot\",…\n$ originalTitle  &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierrot…\n$ isAdult        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ startYear      &lt;dbl&gt; 1894, 1892, 1892, 1892, 1893, 1894, 1894, 1894, 1894, 1…\n$ endYear        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ runtimeMinutes &lt;dbl&gt; 1, 5, 5, 12, 1, 1, 1, 1, 45, 1, 1, 1, 1, 1, 2, 1, 1, 1,…\n$ genres         &lt;chr&gt; \"Documentary,Short\", \"Animation,Short\", \"Animation,Come…\n\n# movie, tvEpisode and tvSeries\ntable(TITLE_BASICS$titleType)\n\n\n       movie        short    tvEpisode tvMiniSeries      tvMovie     tvSeries \n      132246        16735       156768         5932        15048        29992 \n     tvShort    tvSpecial        video    videoGame \n         411         3064         9345         4690 \n\n\n\nMOVIE_COUNT &lt;- TITLE_BASICS |&gt;\n  filter(`titleType` == \"movie\") |&gt;\n  select(`tconst`) |&gt;\n  unique() |&gt;\n  count()\n\nsprintf(\"There are %s movies in the data\", format(MOVIE_COUNT, big.mark = \",\", scientific = FALSE))\n\n[1] \"There are 132,246 movies in the data\"\n\nTV_SERIES_COUNT &lt;- TITLE_BASICS |&gt;\n  filter(`titleType` == \"tvSeries\") |&gt;\n  select(`tconst`) |&gt;\n  unique() |&gt;\n  count()\n\nsprintf(\"There are %s TV Series in the data\", format(TV_SERIES_COUNT, big.mark = \",\", scientific = FALSE))\n\n[1] \"There are 29,992 TV Series in the data\"\n\nTV_EPISODE_COUNT &lt;- TITLE_BASICS |&gt;\n  filter(`titleType` == \"tvEpisode\") |&gt;\n  select(`tconst`) |&gt;\n  unique() |&gt;\n  count()\n\nsprintf(\"There are %s TV Episodes in the data\", format(TV_EPISODE_COUNT, big.mark = \",\", scientific = FALSE))\n\n[1] \"There are 156,768 TV Episodes in the data\"\n\n\n\n# 2.2: Oldest living person in data\nglimpse(NAME_BASICS)\n\nRows: 3,189,865\nColumns: 6\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;dbl&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;dbl&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\nOLDEST &lt;- NAME_BASICS |&gt;\n  filter(is.na(`deathYear`)) |&gt;\n  arrange(`birthYear`) |&gt;\n  select(`primaryName`, `birthYear`, `deathYear`) |&gt;\n  slice_head(n = 100)\n\nOLDEST |&gt;\n  DT::datatable(options = list(pageLength = 5))\n\n\n\n\n\nClearly this isn’t the way to go about this\n\nTITLES_AND_NAMES &lt;- NAME_BASICS |&gt;\n  separate_longer_delim(knownForTitles, delim = \",\") |&gt;\n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  filter(is.na(deathYear), birthYear &gt;= 1908) |&gt; # according to google, the current oldest person alive was born in 1908\n  arrange(birthYear) |&gt;\n  select(primaryName, birthYear, deathYear) |&gt;\n  unique() |&gt;\n  slice_head(n = 5)\n\nTITLES_AND_NAMES |&gt;\n  DT::datatable()\n\n\n\n\n\nBecause there are too many NULL deathYear values, this question can’t really be answered\n\n# 2.3: There is one TV Episode in this data set with a perfect 10/10 rating and at least 200,00 IMDb ratings. What is it? Which series does it belong to?\nglimpse(TITLE_RATINGS)\n\nRows: 374,231\nColumns: 3\n$ tconst        &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt0…\n$ averageRating &lt;dbl&gt; 5.7, 5.6, 6.5, 5.4, 6.2, 5.0, 5.4, 5.4, 5.4, 6.8, 5.2, 7…\n$ numVotes      &lt;dbl&gt; 2096, 283, 2104, 183, 2839, 197, 889, 2243, 215, 7728, 4…\n\nHIGHEST_RATED &lt;- TITLE_RATINGS |&gt;\n  filter(numVotes &gt;= 200000) |&gt;\n  slice_max(order_by = averageRating) |&gt;\n  left_join(TITLE_EPISODES, by = c(\"tconst\" = \"tconst\")) |&gt;\n  inner_join(TITLE_BASICS, by = c(\"tconst\" = \"tconst\")) |&gt;\n  left_join(TITLE_BASICS, by = c(\"parentTconst\" = \"tconst\")) |&gt;\n  select(\n    filmID = `tconst`,\n    seriesName = `primaryTitle.y`,\n    episodeName = `primaryTitle.x`,\n    `seasonNumber`,\n    `episodeNumber`,\n    yearAired = `startYear.x`,\n    `averageRating`,\n    `numVotes`\n  )\n\nHIGHEST_RATED |&gt;\n  DT::datatable()\n\n\n\n\n\nUnsurprisingly, it’s a season 5 episode of Breaking Bad, specifically, the one where Hank gets got\nIf anyone’s interested in a famous scene (and meme) from this episode (Warning: violence and spoilers)\n\n\n  \n\nSPOILERS!!\n\n\n\n\n\nCode\n# 2.4: Which 4 projects is actor Mark Hamill most known for?\n\n# Just guessing beforehand: Star War IV, V, VI, and VA for the Joker in the Batman animated series\n\nMARK_HAMILL &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\")\n\nMARK_HAMILL |&gt; # going to guess the record with multiple titles is the correct Mark Hamill\n  DT::datatable()\n\n\n\n\n\n\n\nMARK_HAMILL &lt;- NAME_BASICS |&gt;\n  filter(nconst == \"nm0000434\") |&gt;\n  separate_longer_delim(knownForTitles, delim = \",\") |&gt;\n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  select(\n    actorID = `nconst`,\n    `primaryName`,\n    `primaryTitle`\n  )\n\nMARK_HAMILL |&gt;\n  DT::datatable()\n\n\n\n\n\nApparently, Star Wars Episode VIII gets a listing before his Joker VA. Hard disagree, but I digress.\n\n\n  \n\nMark Hamill’s Joker is iconic!\n\n\n\n\n# 2.5: What TV series, with more than 12 episodes, has the highest average rating?\nglimpse(TITLE_EPISODES)\n\nRows: 3,023,489\nColumns: 4\n$ tconst        &lt;chr&gt; \"tt0045960\", \"tt0046855\", \"tt0048378\", \"tt0048562\", \"tt0…\n$ parentTconst  &lt;chr&gt; \"tt0044284\", \"tt0046643\", \"tt0047702\", \"tt0047768\", \"tt0…\n$ seasonNumber  &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 8, 1, 10, 6, 2, 8, 4…\n$ episodeNumber &lt;dbl&gt; 3, 4, 6, 10, 4, 20, 5, 2, 20, 6, 2, 3, 2, 10, 17, 5, 1, …\n\nglimpse(TITLE_BASICS)\n\nRows: 374,231\nColumns: 9\n$ tconst         &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt…\n$ titleType      &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"…\n$ primaryTitle   &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Poor Pierrot\",…\n$ originalTitle  &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierrot…\n$ isAdult        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ startYear      &lt;dbl&gt; 1894, 1892, 1892, 1892, 1893, 1894, 1894, 1894, 1894, 1…\n$ endYear        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ runtimeMinutes &lt;dbl&gt; 1, 5, 5, 12, 1, 1, 1, 1, 45, 1, 1, 1, 1, 1, 2, 1, 1, 1,…\n$ genres         &lt;chr&gt; \"Documentary,Short\", \"Animation,Short\", \"Animation,Come…\n\nglimpse(TITLE_RATINGS)\n\nRows: 374,231\nColumns: 3\n$ tconst        &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt0…\n$ averageRating &lt;dbl&gt; 5.7, 5.6, 6.5, 5.4, 6.2, 5.0, 5.4, 5.4, 5.4, 6.8, 5.2, 7…\n$ numVotes      &lt;dbl&gt; 2096, 283, 2104, 183, 2839, 197, 889, 2243, 215, 7728, 4…\n\nTWELVE_EP_SERIES &lt;- TITLE_EPISODES |&gt;\n  group_by(parentTconst) |&gt;\n  summarize(episodeCount = n()) |&gt;\n  filter(episodeCount &gt;= 12) |&gt;\n  inner_join(TITLE_RATINGS, c(\"parentTconst\" = \"tconst\")) |&gt;\n  left_join(TITLE_BASICS, c(\"parentTconst\" = \"tconst\")) |&gt;\n  select(\n    seriesID = `parentTconst`,\n    `primaryTitle`,\n    `startYear`,\n    `endYear`,\n    `episodeCount`,\n    `averageRating`,\n    `numVotes`\n  ) |&gt;\n  arrange(desc(averageRating), desc(episodeCount), desc(numVotes)) |&gt;\n  slice_head(n = 5)\n\n\nTWELVE_EP_SERIES |&gt;\n  DT::datatable()\n\n\n\n\n\nNo clue what these shows are, but here they are.\n\n# 2.6: The TV Series Happy Days (1974-1984) gives us the common idiom \"jump the shark\". The phrase comes from\n# a controversial fifth season episode (aired in 1977) in which a lead character literally jumped over a shark on\n# water skis. Idiomatically, it is used to refer to the moment when a once-great show becomes ridiculous and\n# rapidly loses quality. Is it true that episodes from later seasons of Happy Days have lower\n# average ratings than the early seasons?\n\n# First find the ID for Happy Days\n\nTITLE_BASICS |&gt;\n  filter(primaryTitle == \"Happy Days\", startYear == 1974, endYear == 1984) |&gt;\n  select(`tconst`, `titleType`, `primaryTitle`)\n\n     tconst titleType primaryTitle\n1 tt0070992  tvSeries   Happy Days\n\nglimpse(TITLE_EPISODES)\n\nRows: 3,023,489\nColumns: 4\n$ tconst        &lt;chr&gt; \"tt0045960\", \"tt0046855\", \"tt0048378\", \"tt0048562\", \"tt0…\n$ parentTconst  &lt;chr&gt; \"tt0044284\", \"tt0046643\", \"tt0047702\", \"tt0047768\", \"tt0…\n$ seasonNumber  &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 8, 1, 10, 6, 2, 8, 4…\n$ episodeNumber &lt;dbl&gt; 3, 4, 6, 10, 4, 20, 5, 2, 20, 6, 2, 3, 2, 10, 17, 5, 1, …\n\nHAPPY_DAYS &lt;- TITLE_EPISODES |&gt;\n  filter(parentTconst == \"tt0070992\") |&gt;\n  left_join(TITLE_RATINGS, c(\"tconst\" = \"tconst\")) |&gt;\n  select(\n    -`numVotes`,\n    -`parentTconst`,\n    -`tconst`\n  ) |&gt;\n  group_by(seasonNumber) |&gt;\n  summarize(avgRating = mean(averageRating, na.rm = TRUE))\n\nHAPPY_DAYS |&gt;\n  DT::datatable()\n\n\n\n\nmin_point &lt;- HAPPY_DAYS[which.min(HAPPY_DAYS$avgRating), ]\nmax_point &lt;- HAPPY_DAYS[which.max(HAPPY_DAYS$avgRating), ]\nsharkjump &lt;- HAPPY_DAYS[HAPPY_DAYS$seasonNumber == 5, ]\n\nhighlighted_points &lt;- factor(c(\"Lowest Rating\", \"Highest Rating\", \"Jumped Shark\"),\n  levels = c(\"Lowest Rating\", \"Highest Rating\", \"Jumped Shark\")\n) # Set the order here\n\n\n# Plot ratings over time\nggplot(HAPPY_DAYS, aes(x = seasonNumber, y = avgRating)) +\n  geom_line(size = 1) +\n  geom_point(color = \"#D35400\", size = 2) +\n\n  # Add custom points for min, max, and season 5\n  geom_point(data = min_point, aes(color = highlighted_points[1]), size = 3) +\n  geom_point(data = max_point, aes(color = highlighted_points[2]), size = 3) +\n  geom_point(data = sharkjump, aes(color = highlighted_points[3]), size = 3) +\n\n  # Add labels and formatting\n  labs(title = \"Happy Days Average Rating by Season\", x = \"Season\", y = \"Average Rating\") +\n\n  # Customize ticks for x and y axes\n  scale_x_continuous(breaks = seq(min(HAPPY_DAYS$seasonNumber), max(HAPPY_DAYS$seasonNumber), by = 1)) +\n  scale_y_continuous(labels = label_number(), breaks = seq(floor(min(HAPPY_DAYS$avgRating)), ceiling(max(HAPPY_DAYS$avgRating)), by = 0.5)) +\n\n  # Manually define colors for the highlighted points\n  scale_color_manual(\n    values = c(\"Lowest Rating\" = \"blue\", \"Highest Rating\" = \"red\", \"Jumped Shark\" = \"green\"),\n    name = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n    axis.title.x = element_text(size = 14),\n    axis.title.y = element_text(size = 14),\n    axis.text = element_text(size = 12),\n    # panel.grid.minor = element_blank(),\n    legend.position = \"right\", # Position the legend on the right\n    legend.text = element_text(face = \"bold\", size = 8),\n\n    # Set the background colors\n    panel.background = element_rect(fill = \"gray90\"), # Gray background for the plot area\n    plot.background = element_rect(fill = \"gray90\"), # Gray background for the entire plot\n\n    # Enhance axis lines\n    axis.line = element_line(color = \"black\", size = 1.2), # Change color and thickness of axis lines\n    axis.ticks = element_line(color = \"black\", size = 1), # Change color and thickness of tick marks\n    axis.ticks.length = unit(0.25, \"cm\"), # Adjust length of tick marks\n\n    # Enhance gridlines\n    panel.grid.major = element_line(color = \"gray60\", size = 0.5), # Change color and thickness of major gridlines\n    panel.grid.minor = element_line(color = \"gray60\", size = 0.5) # Change color and thickness of minor gridlines\n  )\n\n\n\n\n\n\n\n\nAs we can see, the shark-jump likely caused an immediate dip in viewership, but it rebounded for the final 3 seasons and went out near the height of its popularity\n\n\nTask 3: What is success?\nHere we create a “success” metric to determine whether or not a film meets our own standards.\nFirst let’s define success. We want to look at two features: * Average Rating * Num Votes Other features of note could be * Crew Size * Run Time\n\n# First let's just get only movie data from 1960 onwards\nMOVIES &lt;- TITLE_BASICS |&gt;\n  filter(titleType == \"movie\", startYear &gt;= 1960)\n\n# Add in ratings\nMOVIES &lt;- MOVIES |&gt;\n  left_join(TITLE_RATINGS, c(\"tconst\" = \"tconst\")) |&gt;\n  select(\n    `tconst`,\n    `primaryTitle`,\n    `isAdult`,\n    releaseYear = `startYear`,\n    `runtimeMinutes`,\n    `genres`,\n    `averageRating`,\n    `numVotes`\n  )\n\n# Add in crew size\nCREWS &lt;- TITLE_PRINCIPALS |&gt;\n  group_by(tconst) |&gt;\n  summarize(castCount = n())\n\nMOVIES &lt;- MOVIES |&gt;\n  left_join(CREWS, c(\"tconst\" = \"tconst\"))\n\n# Count the number of genres in the 'genres' column\nGENRE_COUNT &lt;- MOVIES |&gt;\n  separate_longer_delim(genres, delim = \",\") |&gt; # Split into multiple rows by delimiter\n  group_by(tconst) |&gt; # Group by title to keep track of original rows\n  summarise(genre_count = n(), .groups = \"drop\") # Count the number of genres\n\n\n# Join back to the original MOVIES dataframe if needed\nMOVIES &lt;- MOVIES |&gt;\n  left_join(GENRE_COUNT, by = \"tconst\")\n\n# summary stats\ndescribe(MOVIES)\n\n               vars      n     mean       sd  median  trimmed      mad  min\ntconst*           1 118505 59253.00 34209.59 59253.0 59253.00 43923.51    1\nprimaryTitle*     2 118505 53767.12 30890.58 53903.0 53812.98 39907.14    1\nisAdult           3 118505     0.01     0.09     0.0     0.00     0.00    0\nreleaseYear       4 118505  2004.03    16.86  2010.0  2006.16    13.34 1960\nruntimeMinutes    5 116399   101.65   202.99    96.0    98.24    14.83   17\ngenres*           6 118505   579.73   274.72   633.0   599.44   201.63    1\naverageRating     7 118505     5.88     1.32     6.1     5.95     1.19    1\nnumVotes          8 118505  9392.56 58913.55   473.0  1139.48   498.15  100\ncastCount         9 114101    18.47     4.11    19.0    18.70     2.97    1\ngenre_count      10 118505     2.00     0.83     2.0     2.00     1.48    1\n                   max   range   skew kurtosis     se\ntconst*         118505  118504   0.00    -1.20  99.38\nprimaryTitle*   107056  107055  -0.01    -1.21  89.73\nisAdult              1       1  10.77   113.99   0.00\nreleaseYear       2024      64  -0.94    -0.17   0.05\nruntimeMinutes   51420   51403 224.22 52765.55   0.59\ngenres*           1010    1009  -0.66    -0.48   0.80\naverageRating       10       9  -0.52     0.17   0.00\nnumVotes       2952383 2952283  17.20   456.62 171.14\ncastCount           57      56  -0.44     2.86   0.01\ngenre_count          3       2   0.00    -1.55   0.00\n\n# 90% of movies fall between an average rating of 3.4 and 7.7\nquantile(MOVIES$averageRating, .05)\n\n 5% \n3.4 \n\nquantile(MOVIES$averageRating, .95)\n\n95% \n7.7 \n\n# We can use this to determine both what makes a great move and what makes a flop\n\nFLOPS &lt;- MOVIES |&gt;\n  filter(averageRating &lt;= 3.4)\n\nSUCCESSES &lt;- MOVIES |&gt;\n  filter(averageRating &gt;= 7.7)\n\ndescribe(FLOPS)\n\n               vars    n    mean      sd median trimmed     mad  min      max\ntconst*           1 6162 3081.50 1778.96 3081.5 3081.50 2283.95    1   6162.0\nprimaryTitle*     2 6162 3055.68 1762.50 3054.5 3056.01 2261.71    1   6107.0\nisAdult           3 6162    0.00    0.05    0.0    0.00    0.00    0      1.0\nreleaseYear       4 6162 2010.13   12.33 2013.0 2012.26    8.90 1960   2024.0\nruntimeMinutes    5 5952   98.85  559.05   89.0   89.42   10.38   26  43200.0\ngenres*           6 6162  226.28  128.67  239.0  233.78  170.50    1    396.0\naverageRating     7 6162    2.82    0.52    2.9    2.88    0.44    1      3.4\nnumVotes          8 6162 1333.77 6306.58  334.0  468.67  269.83  100 180239.0\ncastCount         9 5886   18.30    3.86   18.0   18.36    2.97    1     49.0\ngenre_count      10 6162    1.94    0.84    2.0    1.92    1.48    1      3.0\n                  range  skew kurtosis    se\ntconst*          6161.0  0.00    -1.20 22.66\nprimaryTitle*    6106.0  0.00    -1.20 22.45\nisAdult             1.0 20.90   435.00  0.00\nreleaseYear        64.0 -1.67     2.81  0.16\nruntimeMinutes  43174.0 76.99  5933.03  7.25\ngenres*           395.0 -0.36    -1.27  1.64\naverageRating       2.4 -1.09     0.74  0.01\nnumVotes       180139.0 14.03   256.60 80.34\ncastCount          48.0  0.03     3.71  0.05\ngenre_count         2.0  0.12    -1.58  0.01\n\ndescribe(SUCCESSES)\n\n               vars    n     mean        sd median trimmed     mad    min\ntconst*           1 7224  3612.50   2085.53 3612.5 3612.50 2677.58    1.0\nprimaryTitle*     2 7224  3574.23   2063.38 3573.5 3573.97 2651.63    1.0\nisAdult           3 7224     0.00      0.05    0.0    0.00    0.00    0.0\nreleaseYear       4 7224  2004.91     17.78 2011.0 2007.24   14.83 1960.0\nruntimeMinutes    5 6930   115.03     42.59  109.0  111.80   31.13   17.0\ngenres*           6 7224   261.63    111.20  295.0  272.18   94.89    1.0\naverageRating     7 7224     8.10      0.42    8.0    8.03    0.30    7.7\nnumVotes          8 7224 44528.35 188879.33  699.0 3525.70  856.94  100.0\ncastCount         9 6892    16.43      5.12   17.0   16.71    4.45    1.0\ngenre_count      10 7224     1.90      0.84    2.0    1.88    1.48    1.0\n                   max     range  skew kurtosis      se\ntconst*           7224    7223.0  0.00    -1.20   24.54\nprimaryTitle*     7150    7149.0  0.00    -1.20   24.28\nisAdult              1       1.0 21.17   446.38    0.00\nreleaseYear       2024      64.0 -0.93    -0.26    0.21\nruntimeMinutes    1440    1423.0  6.95   157.15    0.51\ngenres*            446     445.0 -0.79    -0.15    1.31\naverageRating       10       2.3  1.51     2.30    0.00\nnumVotes       2952383 2952283.0  6.83    59.67 2222.26\ncastCount           38      37.0 -0.43     0.53    0.06\ngenre_count          3       2.0  0.18    -1.55    0.01\n\n\nSuccesses seem to be longer on average but also confined to a range of 1,440 minutes runtime while flops get a little silly. A lot more people vote for successes (surprising because you’d think people are more likely to respond if they dislike something than if they like it.\n\n# The number of genres used seem to not matter pretty much at all\n\nMode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nMode(SUCCESSES$genres)\n\n[1] \"Documentary\"\n\nMode(FLOPS$genres)\n\n[1] \"Horror\"\n\nhead(sort(desc(table(SUCCESSES$genres))), n = 20)\n\n\n                  Documentary                         Drama \n                        -1083                         -1040 \n                       Comedy                  Comedy,Drama \n                         -289                          -248 \n            Documentary,Music                 Drama,Romance \n                         -241                          -205 \n        Biography,Documentary          Comedy,Drama,Romance \n                         -119                          -112 \n           Action,Crime,Drama             Documentary,Sport \n                         -105                          -105 \n          Documentary,History                      Thriller \n                          -96                           -90 \n         Crime,Drama,Thriller   Biography,Documentary,Music \n                          -81                           -79 \n               Drama,Thriller                   Crime,Drama \n                          -79                           -77 \n                 Drama,Family                           \\\\N \n                          -76                           -70 \nBiography,Documentary,History                     Drama,War \n                          -66                           -65 \n\nhead(sort(desc(table(FLOPS$genres))), n = 20)\n\n\n                 Horror                  Comedy         Horror,Thriller \n                   -956                    -598                    -334 \n                  Drama                Thriller                  Action \n                   -199                    -156                    -150 \n          Comedy,Horror            Comedy,Drama Horror,Mystery,Thriller \n                   -135                     -88                     -87 \n          Horror,Sci-Fi                  Sci-Fi Action,Adventure,Comedy \n                    -84                     -84                     -76 \n   Drama,Horror,Mystery           Action,Sci-Fi          Comedy,Romance \n                    -74                     -73                     -73 \n  Drama,Horror,Thriller      Action,Crime,Drama             Documentary \n                    -70                     -67                     -65 \n           Action,Drama         Action,Thriller \n                    -64                     -62 \n\ntable(SUCCESSES$isAdult)\n\n\n   0    1 \n7208   16 \n\ntable(FLOPS$isAdult)\n\n\n   0    1 \n6148   14 \n\n# This feature doesn't seem to matter, we could probably even drop it\n\nDocumentaries and Dramas are successful while Horror is not. Comedy can go either way.\nMetrics for success: * Good genre (Drama, Documentary) * High number of votes (&gt; 500) * Runtime between 70 minutes and 150 minutes. Dock points for each STD outside of that.\nMetrics for flop: * Bad genre (Horror, Comedy) * Low number of votes (&lt;= 500) * Runtime greater than 200 minutes.\n\n# Define the metric for success function\nmetric_for_success &lt;- function(df) {\n  df &lt;- df |&gt;\n    mutate(\n      # Calculate positive contributions\n      positive_metric = ifelse(str_detect(genres, \"Drama|Documentary\"), 0.2, 0) +\n        ifelse(numVotes &gt;= 500, 0.4, 0) +\n        ifelse(runtimeMinutes &gt;= 70 & runtimeMinutes &lt;= 150, 0.4, 0),\n      \n      # Calculate negative contributions\n      negative_metric = ifelse(str_detect(genres, \"Horror|Comedy\"), -0.4, 0) +\n        ifelse(numVotes &lt; 500 | is.na(numVotes), -0.3, 0) +\n        ifelse(runtimeMinutes &gt; 200, -pmin(0.5, (runtimeMinutes - 200) / 90), 0),\n      \n      # Combine the positive and negative contributions\n      metric = positive_metric + negative_metric,\n      \n      # Bound the metric between -1 and 1\n      metric = pmin(pmax(metric, -1), 1),\n      \n      # Round the metric to 3 decimal places\n      metric = round(metric, 3)\n    ) |&gt;\n    # Drop the intermediate columns (optional)\n    select(-positive_metric, -negative_metric)\n  \n  return(df)\n}\n\n# Apply the metric function to the DataFrame\nMOVIES &lt;- metric_for_success(MOVIES)\n\ntable(MOVIES$metric)\n\n\n    -1 -0.944   -0.8 -0.767 -0.722   -0.7 -0.611   -0.6 -0.567 -0.544 -0.533 \n     9      1      8      1      1    642      1     59      1      5      1 \n  -0.5 -0.478 -0.467 -0.444 -0.433 -0.411   -0.4 -0.389 -0.378 -0.367 -0.356 \n   293      2      1      1      1      2      3      1      2      2      3 \n-0.344 -0.333 -0.322 -0.311   -0.3 -0.289 -0.278 -0.267 -0.256 -0.244 -0.233 \n     1      2      5      2  15056      1      2      2      1      1      1 \n-0.222 -0.211 -0.189 -0.167 -0.144 -0.122 -0.111   -0.1 -0.067 -0.056 -0.033 \n     1      9      3      2      1      1      5   8398      2      1      1 \n-0.022      0  0.022  0.067    0.1  0.111  0.133  0.156  0.167  0.178  0.189 \n     1    420      1      1   7901      1      2      4      1      4      2 \n   0.2  0.211  0.233  0.244  0.256  0.267  0.278    0.3  0.311  0.322  0.333 \n   467      1      1      2      1      2      1  26557      2      2      1 \n 0.344  0.367  0.378  0.389    0.4  0.411  0.422  0.433  0.444  0.456  0.489 \n     1      1      6      2  16669      4      2      2      2      3      6 \n   0.5  0.511  0.522  0.533  0.544  0.556  0.567  0.578  0.589    0.6    0.8 \n     1      5      2      1      2      1      1      4      3  10527   6349 \n     1 \n 22892 \n\n\n\n# 3.1: Choose the top 5-10 movies by my metric to confirm successes\nMOVIES |&gt;\n  filter(metric == 1) |&gt;\n  select(\n    -`isAdult`,\n    -`tconst`,\n    -`genre_count`\n  ) |&gt;\n  sample_n(10) |&gt;\n  DT::datatable()\n\n\n\n\n# This metric works really well in conjunction with a high number of votes\nMOVIES |&gt;\n  arrange(desc(metric), desc(numVotes)) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n# 3.2: Choose 3-5  movies with large numbers of IMDb votes that socre poorly on your success metric and confirm\n# that they are indeed low quality\nMOVIES |&gt;\n  arrange(metric, desc(numVotes)) |&gt;\n  select(\n    `primaryTitle`,\n    `releaseYear`,\n    `numVotes`,\n    `averageRating`,\n    `genres`,\n    `metric`\n  ) |&gt;\n  DT::datatable(options = list(pageLength = 5))\n\n\n\n\n\nI didn’t need a personal metric to tell me that these 5 movies suck.\n\n# 3.3 Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\nNAME_BASICS |&gt;\n  filter(primaryName == \"Stanley Kubrick\") |&gt;\n  separate_longer_delim(knownForTitles, delim = \",\") |&gt;\n  inner_join(MOVIES, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  select(\n    `primaryName`,\n    `primaryTitle`,\n    `averageRating`,\n    `numVotes`,\n    `genres`,\n    `runtimeMinutes`,\n    `metric`\n  ) |&gt;\n  DT::datatable()\n\n\n\n\n\nPretty good\n\n# 3.4 Perform at least one other \"spot check\" validation\n\ncounts &lt;- MOVIES |&gt;\n  summarize(\n    above_7_5_high_metric = sum(averageRating &gt; 7.5 & metric &gt;= 0.6, na.rm = TRUE),\n    between_5_and_7_5_high_metric = sum(averageRating &gt;= 5 & averageRating &lt;= 7.5 & metric &gt;= 0.6, na.rm = TRUE),\n    below_5_high_metric = sum(averageRating &lt; 5 & metric &gt;= 0.6, na.rm = TRUE),\n    above_5_and_7_5_low_metric = sum(averageRating &gt; 7.5 & metric &lt;= 0.3, na.rm = TRUE),\n    between_5_and_7_5_low_metric = sum(averageRating &gt;= 5 & averageRating &lt;= 7.5 & metric &lt;= 0.3, na.rm = TRUE),\n    below_5_low_metric = sum(averageRating &lt; 5 & metric &lt;= 0.3, na.rm = TRUE)\n  )\n\ncounts |&gt;\n  DT::datatable()\n\n\n\n\n\nAlthough the metric is imperfect, it is pretty good at telling us what’s good and what’s not (based on average ratings)\n\n# 3.5: Come up with a numerical threshold for a project to be a ‘success’; that is, determine a value such that movies above `v` are all “solid” or better.\n\n# 0.6 seems reasonable given the above table\nv &lt;- 0.6\n\n\n\nTask 4: What makes a good movie?\nFor this task, we’re examining different trends in success over time.\nA line graph for different groups of films, broken up by popularity of the genre (&gt;5000 films is considered “popular”) and broken up by average rating and the personal average metric score.\n\n\nCode\n# Juuuust incase\navgrtgthrsh &lt;- 6.0\n\n\n# Create a new column indicating success based on averageRating\nMOVIES &lt;- MOVIES |&gt;\n  mutate(\n    success_averageRating = ifelse(averageRating &gt;= avgrtgthrsh, 1, 0),\n    success_metric = ifelse(metric &gt;= v, 1, 0)\n  ) |&gt;\n  mutate(decade = floor(releaseYear / 10) * 10)\n\nMOVIES_GENRES &lt;- MOVIES |&gt;\n  filter(genres != \"\\\\N\", averageRating != \"\\\\N\") |&gt;\n  separate_longer_delim(genres, delim = \",\") |&gt;\n  mutate(genres = trimws(genres)) |&gt;\n  mutate(decade = floor(releaseYear / 10) * 10)\n\n# Calculate total films by genre and decade\ntotal_films_by_genre &lt;- MOVIES_GENRES |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(total_count = n(), .groups = \"drop\")\n\n# Filter genres by count\npopular_genres &lt;- total_films_by_genre |&gt;\n  filter(total_count &gt; 5000) |&gt;\n  select(genres) |&gt;\n  distinct()\n\n# Count successes for averageRating (for popular genres)\nsuccess_by_genre_rating_popular &lt;- MOVIES_GENRES |&gt;\n  filter(genres %in% popular_genres$genres) |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(success_count = sum(success_averageRating, na.rm = TRUE), .groups = \"drop\") |&gt;\n  left_join(total_films_by_genre, by = c(\"decade\", \"genres\")) |&gt;\n  mutate(success_rate = success_count / total_count * 100) |&gt;\n  arrange(decade, desc(success_rate))\n\n# Count successes for metric (for popular genres)\nsuccess_by_genre_metric_popular &lt;- MOVIES_GENRES |&gt;\n  filter(genres %in% popular_genres$genres) |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(success_count = sum(success_metric, na.rm = TRUE), .groups = \"drop\") |&gt;\n  left_join(total_films_by_genre, by = c(\"decade\", \"genres\")) |&gt;\n  mutate(success_rate = success_count / total_count * 100) |&gt;\n  arrange(decade, desc(success_rate))\n\n# Count successes for averageRating (for less popular genres)\nsuccess_by_genre_rating_less &lt;- MOVIES_GENRES |&gt;\n  filter(!(genres %in% popular_genres$genres)) |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(success_count = sum(success_averageRating, na.rm = TRUE), .groups = \"drop\") |&gt;\n  left_join(total_films_by_genre, by = c(\"decade\", \"genres\")) |&gt;\n  mutate(success_rate = success_count / total_count * 100) |&gt;\n  arrange(decade, desc(success_rate))\n\n# Count successes for metric (for less popular genres)\nsuccess_by_genre_metric_less &lt;- MOVIES_GENRES |&gt;\n  filter(!(genres %in% popular_genres$genres)) |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(success_count = sum(success_metric, na.rm = TRUE), .groups = \"drop\") |&gt;\n  left_join(total_films_by_genre, by = c(\"decade\", \"genres\")) |&gt;\n  mutate(success_rate = success_count / total_count * 100) |&gt;\n  arrange(decade, desc(success_rate))\n\n# Plotting Success Rates for Average Rating (Popular Genres)\np1 &lt;- ggplot(success_by_genre_rating_popular, aes(x = decade, y = success_rate, color = genres, group = genres)) +\n  geom_line(size = 1) + # Add line\n  geom_point(size = 3) + # Add points for clarity\n  labs(title = \"Success Rates by Genre (Average Rating - Popular Genres)\", x = \"Decade\", y = \"Success Rate (%)\") +\n  scale_y_continuous(limits = c(0, 100)) + # Set y-axis limits from 0 to 100\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels\n    plot.title = element_text(hjust = 0.5) # Center the title\n  )\n\n# Convert ggplot to plotly for hover functionality\nplt1 &lt;- ggplotly(p1)\n\n# Plotting Success Rates for Metric (Popular Genres)\np2 &lt;- ggplot(success_by_genre_metric_popular, aes(x = decade, y = success_rate, color = genres, group = genres)) +\n  geom_line(size = 1) + # Add line\n  geom_point(size = 3) + # Add points for clarity\n  labs(title = \"Success Rates by Genre (Metric - Popular Genres)\", x = \"Decade\", y = \"Success Rate (%)\") +\n  scale_y_continuous(limits = c(0, 100)) + # Set y-axis limits from 0 to 100\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels\n    plot.title = element_text(hjust = 0.5) # Center the title\n  )\n\n# Convert ggplot to plotly for hover functionality\nplt2 &lt;- ggplotly(p2)\n\n# Plotting Success Rates for Average Rating (Less Popular Genres)\np3 &lt;- ggplot(success_by_genre_rating_less, aes(x = decade, y = success_rate, color = genres, group = genres)) +\n  geom_line(size = 1) + # Add line\n  geom_point(size = 3) + # Add points for clarity\n  labs(title = \"Success Rates by Genre (Average Rating - Less Popular Genres)\", x = \"Decade\", y = \"Success Rate (%)\") +\n  scale_y_continuous(limits = c(0, 100)) + # Set y-axis limits from 0 to 100\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels\n    plot.title = element_text(hjust = 0.5) # Center the title\n  )\n\n# Convert ggplot to plotly for hover functionality\nplt3 &lt;- ggplotly(p3)\n\n# Plotting Success Rates for Metric (Less Popular Genres)\np4 &lt;- ggplot(success_by_genre_metric_less, aes(x = decade, y = success_rate, color = genres, group = genres)) +\n  geom_line(size = 1) + # Add line\n  geom_point(size = 3) + # Add points for clarity\n  labs(title = \"Success Rates by Genre (Metric - Less Popular Genres)\", x = \"Decade\", y = \"Success Rate (%)\") +\n  scale_y_continuous(limits = c(0, 100)) + # Set y-axis limits from 0 to 100\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels\n    plot.title = element_text(hjust = 0.5) # Center the title\n  )\n\n# Convert ggplot to plotly for hover functionality\nplt4 &lt;- ggplotly(p4)\n\n\n\n# 4.1: Which genre has the most \"successs\" in each decade\"?\n# 4.2 Which genre consistently has the most \"successes\"? Which genre used to reliably produce \"successes\" and has fallen out of favor?\n# 4.4: What genre has become more popular in recent years?\n\n# Count successes for averageRating\nsuccess_by_genre_rating &lt;- MOVIES_GENRES |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(success_count = sum(success_averageRating, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(decade, desc(success_count))\n\n# Count successes for metric\nsuccess_by_genre_metric &lt;- MOVIES_GENRES |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(success_count = sum(success_metric, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(decade, desc(success_count))\n\n# Identify the genre with the most successes for each decade (Average Rating)\nmost_successful_genre_rating &lt;- success_by_genre_rating |&gt;\n  group_by(decade) |&gt;\n  slice_max(success_count, n = 2) |&gt;\n  ungroup()\n\n# Identify the genre with the most successes for each decade (Metric)\nmost_successful_genre_metric &lt;- success_by_genre_metric |&gt;\n  group_by(decade) |&gt;\n  slice_max(success_count, n = 2) |&gt;\n  ungroup()\n\nmost_successful_genre_rating |&gt;\n  DT::datatable()\n\n\n\n\nmost_successful_genre_metric |&gt;\n  DT::datatable()\n\n\n\n\n\n\nplt1\n\n\n\n\nplt2\n\n\n\n\nplt3\n\n\n\n\nplt4\n\n\n\n\n\n4.1: Drama and Action films are pretty successful in each decade!\n4.2: Documentaries have the most consistent successes per decade.\n4.2: Horror used to produce a lot of successes but has been on a downward trend each decade.\n4.4: Action movies are on the up-and-up!\nNote: For plt3, there are two blue lines that look similar and seem to form a triangle for Reality TV and News.\n\n# 4.3: What genre has produced the most “successes” since 2010?\n# Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nmost_successful_genre_rating |&gt;\n  DT::datatable()\n\n\n\n\nmost_successful_genre_metric |&gt;\n  DT::datatable()\n\n\n\n\n\nDrama seems to be the answer to both of these\n\n\nTask 5: Identifying the Crew\nHang on to your hats because there’s about to be a lot of data manipulation.\nBasically, we’re going to whittle down the list of actors and directors until we find a group that matches what we’re looking for in producing the next box-office smash hit.\n\n\nCode\n# Filter TITLE_BASICS based on metric threshold and genre\nFILTERED_MOVIES &lt;- MOVIES |&gt;\n  separate_longer_delim(genres, delim = \",\") |&gt;\n  filter(success_metric == 1, genres %in% c(\"Action\", \"Drama\", \"Thriller\", \"Documentary\")) |&gt;\n  group_by(tconst) |&gt;\n  summarize(\n    title = first(primaryTitle), # Adjust according to your dataset\n    year = first(releaseYear), # Adjust according to your dataset\n    metric = first(metric), # Adjust according to your dataset,\n    avgRating = first(averageRating),\n    numVotes,\n    decade = first(decade),\n    castCount = first(castCount),\n    genres = paste(unique(genres), collapse = \", \") # Combine genres into one string\n  )\n\n\nACTORS &lt;- NAME_BASICS |&gt;\n  filter(grepl(\"actor\", primaryProfession, ignore.case = TRUE), is.na(deathYear)) |&gt;\n  separate_longer_delim(primaryProfession, delim = \",\") |&gt;\n  filter(primaryProfession == \"actor\") |&gt;\n  mutate(age = 2024 - birthYear) |&gt;\n  select(-`deathYear`)\n\n# Joining with TITLE_PRINCIPALS\nACTORS_TITLES &lt;- ACTORS |&gt;\n  inner_join(TITLE_PRINCIPALS, by = c(\"nconst\" = \"nconst\")) |&gt;\n  left_join(TITLE_BASICS, by = c(\"tconst\" = \"tconst\")) |&gt;\n  inner_join(FILTERED_MOVIES, by = c(\"tconst\" = \"tconst\")) |&gt;\n  select(\n    `nconst`,\n    `primaryName`,\n    `age`,\n    `tconst`,\n    `primaryTitle`,\n    releaseYear = `startYear`,\n    `decade`,\n    `castCount`,\n    `runtimeMinutes`,\n    genres = `genres.x`,\n    mainGenre = `genres.y`,\n    `metric`,\n    `avgRating`\n  ) |&gt;\n  distinct()\n\nDIRECTORS &lt;- NAME_BASICS |&gt;\n  filter(grepl(\"director\", primaryProfession, ignore.case = TRUE), is.na(deathYear)) |&gt;\n  separate_longer_delim(primaryProfession, delim = \",\") |&gt;\n  filter(primaryProfession == \"director\") |&gt;\n  mutate(age = 2024 - birthYear) |&gt;\n  select(-`deathYear`)\n\n\n# Joining with TITLE_PRINCIPALS\nDIRECTORS_TITLES &lt;- DIRECTORS |&gt;\n  inner_join(TITLE_PRINCIPALS, by = c(\"nconst\" = \"nconst\")) |&gt;\n  left_join(TITLE_BASICS, by = c(\"tconst\" = \"tconst\")) |&gt;\n  inner_join(FILTERED_MOVIES, by = c(\"tconst\" = \"tconst\")) |&gt;\n  select(\n    `nconst`,\n    `primaryName`,\n    `age`,\n    `tconst`,\n    `primaryTitle`,\n    releaseYear = `startYear`,\n    `decade`,\n    `castCount`,\n    `runtimeMinutes`,\n    genres = `genres.x`,\n    mainGenre = `genres.y`,\n    `metric`,\n    `avgRating`\n  ) |&gt;\n  distinct()\n\n# Let's get anyone who's been in a film since at least 2015\nLAST_TEN_YEARS_ACTORS &lt;- ACTORS_TITLES |&gt;\n  filter(releaseYear &gt;= 2015)\n\nLAST_TEN_YEARS_DIRECTORS &lt;- DIRECTORS_TITLES |&gt;\n  filter(releaseYear &gt;= 2015)\n\n# since Action and Drama are the best genres, let's subset to those\n\nBEST_GENRES_ACTORS &lt;- LAST_TEN_YEARS_ACTORS |&gt;\n  filter(mainGenre %in% c(\"Action\", \"Drama\"))\n\nBEST_GENRES_DIRECTORS &lt;- LAST_TEN_YEARS_DIRECTORS |&gt;\n  filter(mainGenre %in% c(\"Action\", \"Drama\"))\n\n# For actors, let's get people who can work with big supporting casts.\n# We don't know if that's what we want, but it'll be nice to have\n\ncast_threshold &lt;- BEST_GENRES_ACTORS |&gt;\n  summarize(threshold = quantile(castCount, 0.95, na.rm = TRUE)) |&gt;\n  pull(threshold)\n\n\nACTORS_CREWS &lt;- BEST_GENRES_ACTORS |&gt;\n  group_by(nconst) |&gt;\n  summarize(median_castCount = median(castCount, na.rm = TRUE)) |&gt;\n  filter(median_castCount &gt;= cast_threshold) |&gt; # Filter for median castCount in the top 5 percentilE\n  ungroup()\n\nACTORS_CAST &lt;- BEST_GENRES_ACTORS |&gt;\n  inner_join(ACTORS_CREWS, by = c(\"nconst\" = \"nconst\")) |&gt;\n  select(\n    -`median_castCount`\n  ) |&gt;\n  distinct()\n\n# Let's pull their best works only\n\nBEST_FILMS_ACTORS &lt;- ACTORS_CAST |&gt;\n  group_by(nconst) |&gt;\n  filter(avgRating == max(avgRating, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# For actors, let's narrow it down to actors whos best film is from this decade\n\nCURRENT_BEST_ACTORS &lt;- BEST_FILMS_ACTORS |&gt;\n  filter(decade == 2020)\n\n# We'll now whittle down directors. Who can get a runtime in our sweet-spot of 70 to 150 minutes?\n\nfiltered_median_runtime &lt;- BEST_GENRES_DIRECTORS |&gt;\n  group_by(nconst) |&gt;\n  summarize(median_runtime = median(runtimeMinutes, na.rm = TRUE)) |&gt; # Calculate median runtime\n  filter(median_runtime &gt;= 70 & median_runtime &lt;= 150) # Filter for median runtime between 70 and 150\n\n# Doing the same but for directors\n\nDIRECTORS_RUNTIME &lt;- BEST_GENRES_DIRECTORS |&gt;\n  inner_join(filtered_median_runtime, by = c(\"nconst\" = \"nconst\"))\n# let's pull their best movies only\n\nBEST_FILMS_DIRECTORS &lt;- DIRECTORS_RUNTIME |&gt;\n  group_by(nconst) |&gt;\n  filter(avgRating == max(avgRating, na.rm = TRUE)) |&gt;\n  ungroup()\n\n\n# Let's remove any director who is also an actor\nNON_ACTOR_DIRECTORS &lt;- BEST_FILMS_DIRECTORS |&gt;\n  anti_join(BEST_FILMS_ACTORS, by = c(\"nconst\" = \"nconst\"))\n\n# For directors, let's narrow it down to actors whos best film is from this decade\nCURRENT_BEST_DIRECTORS &lt;- NON_ACTOR_DIRECTORS |&gt;\n  filter(decade == 2020)\n\n\n\ndim(NON_ACTOR_DIRECTORS)\n\n[1] 15530    14\n\ndim(BEST_FILMS_ACTORS)\n\n[1] 1371   13\n\n\nTaking a quick breather! We just got out data down quite a bit. Let’s keep going.\n\n\nCode\nMOST_POPULAR_ACTORS &lt;- CURRENT_BEST_ACTORS |&gt;\n  left_join(FILTERED_MOVIES, by = c(\"tconst\" = \"tconst\")) |&gt;\n  select(\n    `nconst`,\n    `primaryName`,\n    `age`,\n    `primaryTitle`,\n    `year`,\n    `mainGenre`,\n    avgRating = `avgRating.x`,\n    `numVotes`\n  ) |&gt;\n  arrange(desc(numVotes))\n\n\n# Let's also bring in how many films they've worked on\nACTOR_FILM_CT &lt;- TITLE_PRINCIPALS |&gt;\n  filter(category == \"actor\") |&gt;\n  group_by(nconst) |&gt;\n  summarize(film_count = n())\n\n\nMOST_POPULAR_ACTORS &lt;- MOST_POPULAR_ACTORS |&gt;\n  left_join(ACTOR_FILM_CT, by = c(\"nconst\" = \"nconst\"))\n\nMOST_POPULAR_ACTORS &lt;- MOST_POPULAR_ACTORS |&gt;\n  filter(!is.na(film_count))\n\nMOST_POPULAR_ACTORS |&gt;\n  DT::datatable(options = list(pageLength = 5))\n\n\n\n\n\n\nCode\n# Step 1: Join MOST_POPULAR_ACTORS with TITLE_PRINCIPALS to get tconst (movies the actor was part of)\nactor_movies &lt;- MOST_POPULAR_ACTORS |&gt;\n  inner_join(TITLE_PRINCIPALS, by = \"nconst\") |&gt;\n  select(nconst, tconst)\n\n# Step 2: Join actor_movies with MOVIES to get the average rating of each movie\nactor_movie_ratings &lt;- actor_movies |&gt;\n  inner_join(MOVIES, by = \"tconst\") |&gt;\n  select(nconst, tconst, averageRating)\n\n# Step 3: Calculate the average rating for each actor across their movies\nactor_avg_rating &lt;- actor_movie_ratings |&gt;\n  group_by(nconst) |&gt;\n  summarize(avg_rating = mean(averageRating, na.rm = TRUE))\n\n# Step 4: Join the calculated average rating back to MOST_POPULAR_ACTORS\nMOST_POPULAR_ACTORS &lt;- MOST_POPULAR_ACTORS |&gt;\n  left_join(actor_avg_rating, by = \"nconst\")\n\nMOST_POPULAR_ACTORS &lt;- MOST_POPULAR_ACTORS |&gt;\n  select(\n    `nconst`,\n    `primaryName`,\n    `age`,\n    `primaryTitle`,\n    `year`,\n    `mainGenre`,\n    avgMainMovieRating = `avgRating`,\n    `numVotes`,\n    filmCount = `film_count`,\n    avgActorRating = `avg_rating`\n  )\n\nMOST_POPULAR_DIRECTORS &lt;- CURRENT_BEST_DIRECTORS |&gt;\n  left_join(FILTERED_MOVIES, by = c(\"tconst\" = \"tconst\")) |&gt;\n  select(\n    `nconst`,\n    `primaryName`,\n    `age`,\n    `primaryTitle`,\n    `year`,\n    `mainGenre`,\n    avgRating = `avgRating.x`,\n    `numVotes`\n  ) |&gt;\n  arrange(desc(numVotes))\n\n# Let's also bring in how many films they've worked on\nDIRECTOR_FILM_CT &lt;- TITLE_PRINCIPALS |&gt;\n  filter(category == \"director\") |&gt;\n  group_by(nconst) |&gt;\n  summarize(film_count = n())\n\n\nMOST_POPULAR_DIRECTORS &lt;- MOST_POPULAR_DIRECTORS |&gt;\n  left_join(DIRECTOR_FILM_CT, by = c(\"nconst\" = \"nconst\"))\n\nMOST_POPULAR_DIRECTORS &lt;- MOST_POPULAR_DIRECTORS |&gt;\n  filter(!is.na(film_count))\n\n# Step 1: Join MOST_POPULAR_DIRECTORS with TITLE_PRINCIPALS to get tconst (movies the director was part of)\ndirector_movies &lt;- MOST_POPULAR_DIRECTORS |&gt;\n  inner_join(TITLE_PRINCIPALS, by = \"nconst\") |&gt;\n  select(nconst, tconst)\n\n# Step 2: Join director_movies with MOVIES to get the average rating of each movie\ndirector_movies_ratings &lt;- director_movies |&gt;\n  inner_join(MOVIES, by = \"tconst\") |&gt;\n  select(nconst, tconst, averageRating)\n\n# Step 3: Calculate the average rating for each director across their movies\ndirector_avg_rating &lt;- director_movies_ratings |&gt;\n  group_by(nconst) |&gt;\n  summarize(avg_rating = mean(averageRating, na.rm = TRUE))\n\n# Step 4: Join the calculated average rating back to MOST_POPULAR_DIRECTORS\nMOST_POPULAR_DIRECTORS &lt;- MOST_POPULAR_DIRECTORS |&gt;\n  left_join(director_avg_rating, by = \"nconst\")\n\n\n\n\nMOST_POPULAR_DIRECTORS &lt;- MOST_POPULAR_DIRECTORS |&gt;\n  select(\n    `nconst`,\n    `primaryName`,\n    `age`,\n    `primaryTitle`,\n    `year`,\n    `mainGenre`,\n    avgMainMovieRating = `avgRating`,\n    `numVotes`,\n    filmCount = `film_count`,\n    avgDirectorRating = `avg_rating`\n  )\n\n\n\n# Looking at the dimensions of our stratified dataframes\ndim(MOST_POPULAR_ACTORS)\n\n[1] 474  10\n\ndim(MOST_POPULAR_DIRECTORS)\n\n[1] 3254   10\n\n\n\nMOST_POPULAR_ACTORS |&gt;\n  DT::datatable()\n\n\n\n\n\nLooking at directors now\n\n\nCode\n# Identify the directors with the highest values for numVotes, filmCount, and avgDirectorRating\nhighest_votes &lt;- MOST_POPULAR_DIRECTORS |&gt; filter(numVotes == max(numVotes, na.rm = TRUE))\nhighest_film_count &lt;- MOST_POPULAR_DIRECTORS |&gt; filter(filmCount == max(filmCount, na.rm = TRUE))\nhighest_avg_rating &lt;- MOST_POPULAR_DIRECTORS |&gt; filter(avgDirectorRating == max(avgDirectorRating, na.rm = TRUE))\n\n# Combine the labels into one data frame\nlabels_df &lt;- bind_rows(highest_votes, highest_film_count, highest_avg_rating)\n\n# Create the scatter plot\nggplot(MOST_POPULAR_DIRECTORS, aes(x = filmCount, y = numVotes, color = avgDirectorRating)) +\n  geom_point(size = 3) + # Add points with size 3\n\n  scale_color_gradient(low = \"blue\", high = \"red\") + # Color gradient from blue (low) to red (high)\n\n  scale_y_continuous(labels = scales::comma, limits = c(0, 500000)) + # Adjust y-axis to max at 500,000\n\n  labs(\n    title = \"Directors' Film Count vs Number of Votes\",\n    x = \"Film Count\",\n    y = \"Number of Votes\",\n    color = \"Avg Director Rating\" # Label for the color legend\n  ) +\n  \n  # Use ggrepel for better label placement\n  geom_text_repel(\n    data = labels_df, aes(label = primaryName),\n    color = \"black\", size = 4, fontface = \"bold\"\n  ) +\n\n  theme_minimal(base_size = 15) + # Increase font size for better readability\n  theme(\n    plot.background = element_rect(fill = \"darkgray\"),\n    panel.background = element_rect(fill = \"darkgray\"),\n    axis.line = element_line(color = \"white\", size = 1.2),\n    axis.text = element_text(color = \"white\"), # Set axis text color to white\n    axis.title = element_text(color = \"white\", face = \"bold\"), # Bolden axis titles\n    plot.title = element_text(hjust = 0.5, color = \"white\", face = \"bold\"), # Center the title and bold it\n    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels if needed\n    plot.margin = unit(c(1, 1, 1, 1.5), \"lines\") # Add extra space to avoid clipping labels\n  )\n\n\n\n\n\n\n\n\n\nThe two names are the highest Film Count and highest Average Director Rating.\n\nMOST_POPULAR_DIRECTORS |&gt;\n  DT::datatable()\n\n\n\n\n\nRian Johnson seems like a solid choice from the data\n\nMOST_POPULAR_ACTORS |&gt;\n  filter(filmCount &gt;= 10, mainGenre == \"Action\") |&gt;\n  arrange(desc(avgActorRating)) |&gt;\n  DT::datatable()\n\n\n\n\n# Jacob Batalon and John DiMaggio\nMOST_POPULAR_ACTORS |&gt;\n  filter(primaryName %in% c(\"Jacob Batalon\", \"John DiMaggio\")) |&gt;\n  DT::datatable()\n\n\n\n\n\nJacob Batalon and John DiMaggio seem to have some good experience with action films and are fairly popular.\n\n\nTask 6: Remaking a classic\nFor this, we’re going to pick an Action movie as it is one of the best-performing genres.\nWe need something from 1998 or earlier (&lt;= 25 years), and preferably something with a rating of less than 7.5, as remaking something that’s highly rated will just make people mad and not give us room to explore our film.\n\nFILTERED_MOVIES |&gt;\n  filter(year &lt;= 1998, grepl(\"action\", genres, ignore.case = TRUE), avgRating &lt;= 7.5) |&gt;\n  arrange(desc(numVotes)) |&gt;\n  unique() |&gt;\n  DT::datatable()\n\n\n\n\n# Independence Day seems like a good choice, let's make sure there's only one of it though\n\nFILTERED_MOVIES |&gt;\n  filter(title == \"Independence Day\") |&gt;\n  DT::datatable()\n\n\n\n\n\nLooks like we’re good to go with remaking Independence Day using this cast and crew!"
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Mini Project 3",
    "section": "",
    "text": "With the 2024 election in the rear-view mirror, now seems to be as good of a time as any to reflect on the electoral process in the United States.\nFiguring out the best way to represent the citizens is an ongoing debate in democracies. Through our representative democracy in the United States through, we elect members of Congress and the President to lead the Federal government on cycles of 2 years for a Representative and 6 years for a Senator, while the Presidential cycle is an election every 4 years.\nThis project is going to look at some election data from 1976 through 2020 for both the U.S. House of Representatives and the President, before ultimately asking and (lightly) answering if there is a better way to do our current election system for President, which involves delegating votes through the Electoral College."
  },
  {
    "objectID": "mp3/mp03.html",
    "href": "mp3/mp03.html",
    "title": "Mini Project 3",
    "section": "",
    "text": "TASK 0\n\n\nCode\nif (!require(\"readr\")) install.packages(\"readr\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"DT\")) install.packages(\"DT\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"gganimate\")) install.packages(\"gganimate\")\nif (!require(\"gifski\")) install.packages(\"gifski\")\nif (!require(\"plotly\")) install.packages(\"plotly\")\n\nlibrary(readr)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(plotly)\n\n\nTASK 1\n\n\n\n\n\n\nTASK 2\n\n\nCode\n# Function to get district/congressional shapefiles\nget_cdmaps_file &lt;- function(fname, folder = \"congressional_shapefiles\") {\n  # Base URL for downloading\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n  \n  # Add file extension\n  fname_ext &lt;- paste0(fname, \".zip\")\n  \n  # Set the full destination path, including the folder and file name\n  destfile &lt;- file.path(folder, fname_ext)\n  \n  # Create the folder if it doesn't exist\n  if (!dir.exists(folder)) {\n    dir.create(folder)\n  }\n  \n  # Download the file if it doesn't already exist in the folder\n  if (!file.exists(destfile)) {\n    FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n    download.file(FILE_URL, destfile = destfile)\n    cat(\"Downloaded:\", fname_ext, \"\\n\")\n  } else {\n  }\n}\n\n# Define range of districts, we want from 1976 through 2012\nstart &lt;- 94\nend &lt;- 112\n\n# Loop through each district number and download the file\nfor (i in start:end) {\n  district_code &lt;- sprintf(\"districts%03d\", i)\n  get_cdmaps_file(district_code)\n}\n\n\nTASK 3.1\n\n\nCode\n# Create table of electoral votes\nevotes &lt;- house |&gt;\n  group_by(state, year) |&gt;\n  summarize(\n    electoral_votes = n_distinct(district) + 2, # Num districts + 2\n    .groups = 'drop'\n  )\n\n# Have to manually input for DC\nevotes &lt;- evotes |&gt;\n  bind_rows(\n    data.frame(state = \"DISTRICT OF COLUMBIA\", year = 1976, electoral_votes = 3),\n    data.frame(state = \"DISTRICT OF COLUMBIA\", year = 2022, electoral_votes = 3)\n  )\n\n# View New York's electoral votes over the decades\nevotes |&gt;\n  filter(state == \"NEW YORK\", year %in% c(1980, 2000, 2020))\n\n\n# A tibble: 3 × 3\n  state     year electoral_votes\n  &lt;chr&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n1 NEW YORK  1980              41\n2 NEW YORK  2000              33\n3 NEW YORK  2020              29\n\n\n\n\nCode\n# Electoral Votes change from 1976 to 2022\nevotes_overtime &lt;- evotes |&gt;\n  group_by(state) |&gt;\n  mutate(votes_change = electoral_votes[year == 2022] - electoral_votes[year == 1976],\n         .groups = 'drop'\n         ) |&gt;\n  filter(year == 2022) |&gt;\n  select(state,electoral_votes, votes_change)\n\n# Identify the top 3 increases and decreases\ntop_increase &lt;- evotes_overtime |&gt;\n  ungroup() |&gt;\n  slice_max(order_by = votes_change, n=3)\n\ntop_decrease &lt;- evotes_overtime |&gt;\n  ungroup() |&gt;\n  arrange(votes_change) |&gt;\n  slice_head(n=3)\n\n# Add a 'highlight' column to label the states for plotting\nstate_changes &lt;- evotes_overtime |&gt;\n  mutate(\n    highlight = case_when(\n      state %in% top_increase$state ~ \"increase\",\n      state %in% top_decrease$state ~ \"decrease\",\n      TRUE ~ \"normal\"\n    )\n  )\n\n# Barplot of changes overtime\nggplot(state_changes, aes(x = reorder(state, votes_change), y = votes_change, fill = votes_change)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_gradient2(\n    low = \"red\",\n    mid = \"gray\",\n    high = \"green\",\n    midpoint = 0,   # Center the color scale\n    guide = \"none\"  # Removes the legend\n  ) +\n  labs(\n    x = \"State\",\n    y = \"Electoral Votes Change\",\n    title = \"Change in Electoral College Votes from 1976 to 2022 by State\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create the line graph with ggplot2\nline_graph &lt;- ggplot(evotes, aes(x = year, y = electoral_votes, group = state, color = state)) +\n  geom_line() +\n  geom_point() +\n  scale_color_viridis_d() +\n  labs(\n    x = \"Year\",\n    y = \"Electoral Votes\",\n    title = \"Electoral Votes by State from 1976 to 2012 (Interactive)\",\n    subtitle = \"Line Graph of Electoral Votes Over Time\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1),\n    legend.position = \"none\"\n  )\n\n# Convert the ggplot2 plot to a plotly plot for interactivity\ninteractive_plot &lt;- ggplotly(line_graph)\n\n# Display the interactive plot\ninteractive_plot\n\n\n\n\n\n\nTASK 3.2\n\n# Let's find this instance\nhouse |&gt;\n  filter(year==2022, state==\"NEW YORK\", district==12) |&gt;\n  group_by(candidate) |&gt;\n  summarize(votes = sum(candidatevotes)) |&gt;\n  arrange(desc(votes))  |&gt;\n  DT::datatable()\n\n\n\n\n# Find instance but also grouped on  'party' instead of candidate\nhouse |&gt;\n  filter(year == 2022, state == \"NEW YORK\", district == 12) |&gt;\n  group_by(party) |&gt;\n  summarize(votes = sum(candidatevotes)) |&gt;\n  arrange(desc(votes)) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\nCode\n# First let's find races that were really close. Let's do this by defining a \"% of total vote column\"\n# Create pctvote_party and pctvote_candidate columns\nhouse &lt;- house |&gt;\n  # For pctvote_party, group by year, state, and party\n  group_by(year, state, district, party) |&gt;\n  mutate(pctvote_party = candidatevotes / totalvotes) |&gt;\n  # For pctvote_candidate, group by year, state, and candidate\n  group_by(year, state, district, candidate) |&gt;\n  mutate(pctvote_candidate = sum(candidatevotes) / totalvotes) |&gt;\n  # Ungroup to finish\n  ungroup() |&gt;\n  add_count(year, state, district, candidate, name = \"ballotcount\")\n\n# Let's find the most instances of multiple ballots\nhouse_votes &lt;- house |&gt; # Start with just the cols we want\n  select(year, state, district, stage,\n         candidate, ballotcount,party,\n         candidatevotes,totalvotes,\n         pctvote_party, pctvote_candidate\n         ) |&gt; \n  group_by(year, state, candidate) |&gt; # return anything where the percentage vote for the candidate fell into a reasonable range where it could be overturned\n  filter(all(pctvote_candidate &gt; 0.3), all(pctvote_candidate &lt; 0.7)) |&gt; \n  ungroup() |&gt;\n  group_by(year, state, district) |&gt;\n  filter(any(ballotcount &gt;= 2),\n         all(pctvote_party &lt;= 0.5), # If any of the party votes have over 50%, it won't matter what the rest are\n         all(pctvote_candidate &gt; 0.3), all(pctvote_candidate &lt; 0.7)) |&gt;  \n  ungroup() |&gt;\n  filter(n_distinct(c(year, state, district)) &gt; 1) |&gt;\n  group_by(year, state, district) |&gt;\n  mutate(max_pctvote_candidate = pctvote_candidate == max(pctvote_candidate)) |&gt;\n  ungroup() |&gt;\n  group_by(year, state, district) |&gt;\n  mutate(max_pctvote_party = pctvote_party == max(pctvote_party)) |&gt;\n  ungroup() |&gt;\n  mutate(max_pctvote_candidate = ifelse(max_pctvote_candidate, 1, 0),\n         max_pctvote_party = ifelse(max_pctvote_party, 1, 0))\n\nhouse_votes |&gt;\n  filter(year == 2000, state == \"CONNECTICUT\", district == 2) |&gt;\n  select(year, state, district, candidate, party, ballotcount, candidatevotes, pctvote_candidate, pctvote_party, max_pctvote_party, max_pctvote_candidate) |&gt;\n  DT::datatable()\n\n\n\n\n\n\nIn Connecticut’s 2nd District in 2000, Sam Gejdenson’s Democratic party received the most votes, however candidate Rob Simmons on the Independent and Republican ticket won the vote by a razor-thin margin that required votes from both parties\nTASK 3.3\n\n\nCode\n# Let's change up the presidents table\n# First grouping all of the parties by state, year, and district\n# using `party_simplified`\npresidents_states &lt;- presidents |&gt;\n  group_by(year, state, party_simplified) |&gt;\n  summarize(partyvotes = sum(candidatevotes)) |&gt;\n  ungroup() |&gt;\n  group_by(year, state) |&gt;\n  mutate(totalvotes = sum(partyvotes)) |&gt;\n  ungroup() |&gt;\n  mutate(pctvotes = if_else(is.na(partyvotes), 0, partyvotes / totalvotes))\n\n# Creating a `party_simplified` column\nparty_dict &lt;- presidents |&gt;\n  distinct(party_simplified, party_detailed) |&gt;\n  deframe() # This converts the two columns into a named vector\n\nhouse &lt;- house |&gt;\n  mutate(\n    party_simplified = case_when(\n      party %in% names(party_dict) ~ party,  # If the party matches one in the dictionary\n      is.na(party) ~ \"OTHER\",               # If the party is NA\n      TRUE ~ \"OTHER\"                        # If the party is not found in the dictionary\n    )) \n\n# Create the same grouped df as for presidents\nhouse_states &lt;- house |&gt;\n  group_by(year, state, party_simplified) |&gt;\n  summarize(partyvotes = sum(candidatevotes)) |&gt;\n  ungroup() |&gt;\n  group_by(year, state) |&gt;\n  mutate(totalvotes = sum(partyvotes)) |&gt;\n  ungroup() |&gt;\n  mutate(pctvotes = if_else(is.na(partyvotes), 0, partyvotes / totalvotes))\n\n# Merge the two state pct dfs\nmerged_states &lt;- presidents_states |&gt;\n  left_join(house_states, by = c(\"year\", \"state\", \"party_simplified\"), suffix = c(\"_president\", \"_house\")) |&gt;\n  mutate(across(ends_with(\"_house\"), ~coalesce(.x, 0))) |&gt; # Replace NAs in columns ending with _house with 0\n  filter(party_simplified %in% c(\"DEMOCRAT\",\"REPUBLICAN\")) |&gt; # Yes we could look at libertarian and other, but it seems a bit overkill for this\n  rename(`party` = `party_simplified`) |&gt;\n  mutate(pctdiff = abs(pctvotes_president - pctvotes_house)) |&gt;\n  mutate(\n    pctdiff = abs(pctvotes_president - pctvotes_house),  # Create percentage difference column\n    pctdiff_cat = case_when(                             \n      pctdiff &lt; 0.35 ~ \"Low\",\n      pctdiff &gt;= 0.35 & pctdiff &lt;= 0.65 ~ \"Medium\",\n      pctdiff &gt; 0.65 ~ \"High\"\n    )\n  ) |&gt;\n  filter(partyvotes_house &gt; 1, partyvotes_president &gt; 1) |&gt;\n  mutate(pctvotes_president = round(pctvotes_president,4),\n         pctvotes_house = round(pctvotes_house, 4),\n         pctdiff = round(pctdiff, 4))\n\nsummarized_data &lt;- merged_states |&gt;\n  group_by(pctdiff_cat) |&gt;\n  summarize(n = n())  # Summarizing the counts for each category\n\n# Create the bar plot\nggplot(summarized_data, aes(x = pctdiff_cat, y = n, fill = pctdiff_cat)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +  # stat = \"identity\" uses the actual y-values\n  labs(\n    title = \"Distribution of Percentage `Difference` Categories\",\n    x = \"pctdiff Category\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Low\" = \"darkgreen\", \"Medium\" = \"darkblue\", \"High\" = \"darkred\"))  # Customize colors\n\n\n\n\n\n\n\n\n\nCode\n# These are the instances where there was a noticeable difference\nmerged_states |&gt;\n  filter(pctdiff_cat == \"Medium\") |&gt;\n  arrange(desc(pctdiff)) |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = -1,\n      columnDefs = list(\n        # Adding commas for these columns\n        list(\n          targets = c(4, 5, 7, 8),\n          render = JS(\n            \"function(data, type, row, meta) {\",\n            \"  return type === 'display' ? data.toString().replace(/\\\\B(?=(\\\\d{3})+(?!\\\\d))/g, ',') : data;\",  # Adding commas\n            \"}\"\n          )\n        ),\n        # Formatting as percentages for columns 6, 9, and 10\n        list(\n          targets = c(6, 9, 10),\n          render = JS(\n            \"function(data, type, row, meta) {\",\n            \"  return type === 'display' ? (data * 100).toFixed(2) + '%' : data;\",  # Formatting as percentage\n            \"}\"\n          )\n        )\n      )\n    )\n  )\n\n\n\n\n\n\nCode\n# Diff by party\nmerged_states |&gt;\n  filter(pctdiff_cat == \"Medium\") |&gt;\n  group_by(party) |&gt;\n  summarize(n())\n\n\n# A tibble: 2 × 2\n  party      `n()`\n  &lt;chr&gt;      &lt;int&gt;\n1 DEMOCRAT      11\n2 REPUBLICAN     7\n\n\nCode\n# Diff by states\nmerged_states |&gt;\n  filter(pctdiff_cat == \"Medium\") |&gt;\n  group_by(state) |&gt;\n  summarize(count = n()) |&gt;\n  arrange(desc(count))\n\n\n# A tibble: 7 × 2\n  state         count\n  &lt;chr&gt;         &lt;int&gt;\n1 HAWAII            4\n2 VERMONT           4\n3 NEVADA            3\n4 ARKANSAS          2\n5 LOUISIANA         2\n6 NORTH DAKOTA      2\n7 WEST VIRGINIA     1\n\n\nTASK 4\n\n# Create a function to automatically download the shape files\n\nread_shp_from_zip &lt;- function(file) {\n  td &lt;- tempdir()\n  zip_contents &lt;- unzip(file, exdir = td)\n  fname_shp &lt;- zip_contents[grepl(\"\\\\.shp$\", zip_contents)] # filter for .shp files\n  shpfl &lt;- read_sf(fname_shp) # Read the .shp file\n  return(shpfl) # Return the shpfl\n}\n\nTask 5\n\n# Find which file will have the 2000 election\nfiles_dict &lt;- read_csv(\"district_shapefiles.csv\")\n\nfiles_dict |&gt;\n  DT::datatable(options=list(pageLength = -1))\n\n\n\n\n\n\n\nCode\nfile &lt;- \"congressional_shapefiles/districts106.zip\"\n\n\nshpfile &lt;- read_shp_from_zip(file)\n\n\n#####\n# Get electoral votes from 2000\nevotes_2000 &lt;- evotes |&gt;\n  filter(year == 2000) |&gt;\n  select(-year)\n\n# Get info from presidents table for that year\nbush_v_gore &lt;- presidents |&gt;\n  filter(year == 2000) |&gt;\n  group_by(state, party_simplified) |&gt;\n  summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(state) |&gt;\n  slice_max(total_votes, n = 1) |&gt;\n  ungroup() |&gt;\n  select(state, party_simplified) |&gt; \n  rename(winner = party_simplified)\n\n# get info for our shapefile\ndist106sf &lt;- shpfile |&gt;\n  mutate(STATENAME = toupper(trimws(STATENAME))) |&gt;\n  left_join(bush_v_gore, by = c(\"STATENAME\" = \"state\")) |&gt;\n  left_join(evotes_2000, by = c(\"STATENAME\" = \"state\"))\n\n# Aggregate shapefile to the state level\nstates_sf &lt;- shpfile |&gt;\n  mutate(\n    STATENAME = toupper(trimws(STATENAME)), # ensure no white space and state names are consistent\n    geometry = st_make_valid(geometry)\n  ) |&gt;\n  group_by(STATENAME) |&gt;\n  summarize(geometry = st_union(geometry), .groups = \"drop\")\n\n# Merge aggregated shapefile with election results and electoral votes data\nstates_sf &lt;- states_sf |&gt;\n  left_join(bush_v_gore, by = c(\"STATENAME\" = \"state\")) |&gt;\n  left_join(evotes_2000, by = c(\"STATENAME\" = \"state\"))\n\n# Some smaller states are hard to see, let's try to get their info off the map\nlabel_positions &lt;- data.frame(\n  STATENAME = c(\"MASSACHUSETTS\", \"DELAWARE\", \"MARYLAND\", \"RHODE ISLAND\",\n                \"DISTRICT OF COLUMBIA\", \"NEW JERSEY\", \"CONNECTICUT\"),\n  latitude = c(-67, -75, -75, -67, -76, -74, -72),\n  longitude = c(45, 40, 39, 42, 39, 41, 41.5)\n)\n\n# Merge with `states_sf` to include positions in the spatial data\nstates_sf &lt;- states_sf |&gt; left_join(label_positions, by = \"STATENAME\")\n\n\n\nsmall_states &lt;- c(\"MASSACHUSETTS\", \"DELAWARE\", \"MARYLAND\", \"RHODE ISLAND\",\n                  \"DISTRICT OF COLUMBIA\", \"NEW JERSEY\", \"CONNECTICUT\")\n\n# Create main U.S. map with state-level electoral votes\ncont_us &lt;- ggplot(states_sf) +\n  geom_sf(aes(\n    geometry = geometry,\n    fill = winner\n  ), color = \"black\") +\n  # Add electoral votes text for states not in `small_states`\n  geom_sf_text(\n    data = states_sf |&gt; filter(!STATENAME %in% small_states),\n    aes(label = electoral_votes),\n    color = \"cornsilk2\", size = 5\n  ) +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue4\", \"REPUBLICAN\" = \"darkred\")) +\n  theme_minimal() +\n  labs(\n    title = \"Presidential Election State Results 2000\\nGeorge W. Bush vs Albert A. Gore\",\n    subtitle = \"Map of United States with Electoral Votes\",\n    fill = \"Party\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  coord_sf(xlim = c(-130, -60), ylim = c(20, 50), expand = FALSE)\n\n# Add labels and connecting lines for small states\ncont_us &lt;- cont_us +\n  geom_text(\n    data = states_sf |&gt; filter(STATENAME %in% small_states),\n    aes(x = latitude, y = longitude, label = electoral_votes),\n    color = \"black\", size = 5, fontface = \"bold\"\n  ) +\n  geom_segment(\n    data = states_sf |&gt; filter(STATENAME %in% small_states),\n    aes(\n      x = st_coordinates(st_centroid(geometry))[,1], \n      y = st_coordinates(st_centroid(geometry))[,2],\n      xend = latitude,\n      yend = longitude\n    ),\n    color = \"gray\",\n    size = 0.5\n  )\n\n# Create Alaska and Hawaii insets with state-level electoral votes\n\n# Alaska Inset\nalaska_sf &lt;- states_sf[states_sf$STATENAME == \"ALASKA\", ]\ninset_alaska &lt;- ggplot(alaska_sf) +\n  geom_sf(aes(\n    geometry = geometry,\n    fill = winner\n  ), color = \"black\") +\n  geom_sf_text(aes(\n    label = electoral_votes\n  ), color = \"cornsilk2\", size = 5) +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue4\", \"REPUBLICAN\" = \"darkred\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  coord_sf(xlim = c(-180, -140), ylim = c(50, 72), expand = FALSE)\n\n# Hawaii Inset\nhawaii_sf &lt;- states_sf[states_sf$STATENAME == \"HAWAII\", ]\ninset_hawaii &lt;- ggplot(hawaii_sf) +\n  geom_sf(aes(\n    geometry = geometry,\n    fill = winner\n  ), color = \"black\") +\n  geom_sf_text(aes(\n    label = electoral_votes\n  ), color = \"cornsilk2\", size = 5) +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue4\", \"REPUBLICAN\" = \"darkred\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  coord_sf(xlim = c(-161, -154), ylim = c(18, 23), expand = FALSE)\n\n# Combine everything, with Alaska and Hawaii insets\nbush_v_gore_map &lt;- cont_us +\n  annotation_custom(ggplotGrob(inset_alaska),\n                    xmin = -120, xmax = -130, # Adjust position for Alaska\n                    ymin = 15, ymax = 40\n  ) +\n  annotation_custom(ggplotGrob(inset_hawaii),\n                    xmin = -115, xmax = -100, # Adjust position for Hawaii\n                    ymin = 20, ymax = 30\n  )\n\n# Display the map\nprint(bush_v_gore_map)\n\n\n\n\n\n\n\n\n\nTASK 6\n\n\nCode\n# Sequential list for election years\nelection_years &lt;- seq(1976, 2012, by = 4)\n\n\nwinner &lt;- function(election_year) {\n  presidents |&gt;\n    filter(year == election_year) |&gt;\n    group_by(state, year, party_simplified) |&gt;\n    summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n    group_by(state) |&gt;\n    slice_max(total_votes, n = 1) |&gt;\n    ungroup() |&gt;\n    select(state, year, party_simplified) |&gt; \n    rename(winner = party_simplified)\n}\n\n# Calculate total votes, include candidate name\nstate_results &lt;- presidents |&gt;\n  filter(party_simplified %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, state, party_simplified) |&gt;\n  summarize(\n    totalvotes = sum(candidatevotes),\n    candidate = first(candidate), # Assuming `candidate` column exists\n    .groups = \"drop\"\n  )\n\n\n# Left-join the evotes table\nstate_results &lt;- state_results |&gt;\n  left_join(evotes, by = c(\"state\", \"year\"))\n\n# Determine the winner for each state and year\nstate_results &lt;- state_results |&gt;\n  group_by(year, state) |&gt;\n  mutate(\n    is_winner = totalvotes == max(totalvotes) # Flag the winning party\n  ) |&gt;\n  ungroup() |&gt;\n  filter(is_winner == TRUE) |&gt;\n  rename(`party` = `party_simplified`)\n\n# View the results\nprint(state_results)\n\n\n# A tibble: 612 × 7\n    year state              party totalvotes candidate electoral_votes is_winner\n   &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;lgl&gt;    \n 1  1976 ALABAMA            DEMO…     659170 CARTER, …               9 TRUE     \n 2  1976 ALASKA             REPU…      71555 FORD, GE…               3 TRUE     \n 3  1976 ARIZONA            REPU…     418642 FORD, GE…               6 TRUE     \n 4  1976 ARKANSAS           DEMO…     498604 CARTER, …               6 TRUE     \n 5  1976 CALIFORNIA         REPU…    3882244 FORD, GE…              45 TRUE     \n 6  1976 COLORADO           REPU…     584278 FORD, GE…               7 TRUE     \n 7  1976 CONNECTICUT        REPU…     719261 FORD, GE…               8 TRUE     \n 8  1976 DELAWARE           DEMO…     122461 CARTER, …               3 TRUE     \n 9  1976 DISTRICT OF COLUM… DEMO…     137818 CARTER, …               3 TRUE     \n10  1976 FLORIDA            DEMO…    1636000 CARTER, …              17 TRUE     \n# ℹ 602 more rows\n\n\nCode\noverall_winners &lt;- state_results |&gt;\n  filter(is_winner == TRUE) |&gt; # Keep only state winners\n  group_by(year, party, candidate) |&gt; # Group by year, party, and candidate\n  summarize(\n    total_evotes = sum(electoral_votes, na.rm = TRUE), # Sum electoral votes\n    .groups = \"drop\"\n  ) |&gt;\n  group_by(year) |&gt; # Group by year to determine the overall winner\n  slice_max(total_evotes, n = 1, with_ties = FALSE) |&gt; # Take the top party-candidate for each year\n  ungroup() |&gt;\n  select(year, winning_party = party, candidate, total_evotes) |&gt; # Select relevant columns\n  arrange(year) # Sort by year\n\nprint(overall_winners)\n\n\n# A tibble: 12 × 4\n    year winning_party candidate           total_evotes\n   &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;                      &lt;dbl&gt;\n 1  1976 DEMOCRAT      CARTER, JIMMY                297\n 2  1980 REPUBLICAN    REAGAN, RONALD               448\n 3  1984 REPUBLICAN    REAGAN, RONALD               525\n 4  1988 REPUBLICAN    BUSH, GEORGE H.W.            426\n 5  1992 DEMOCRAT      CLINTON, BILL                367\n 6  1996 DEMOCRAT      CLINTON, BILL                376\n 7  2000 REPUBLICAN    BUSH, GEORGE W.              271\n 8  2004 REPUBLICAN    BUSH, GEORGE W.              286\n 9  2008 DEMOCRAT      OBAMA, BARACK H.             361\n10  2012 DEMOCRAT      OBAMA, BARACK H.             329\n11  2016 REPUBLICAN    TRUMP, DONALD J.             305\n12  2020 DEMOCRAT      BIDEN, JOSEPH R. JR          306"
  },
  {
    "objectID": "mp03.html#task-3.1-flipped",
    "href": "mp03.html#task-3.1-flipped",
    "title": "Mini Project 3",
    "section": "TASK 3.1: Flipped",
    "text": "TASK 3.1: Flipped\n\nWhich states have gained and lost the most seats in the U.S. House of Representatives between 1976 and 2022?\n\nIn the U.S., the lower-body of Congress, the U.S. House of Representatives, may have [no-more than 435 total Representatives at any given] time(https://www.house.gov/representatives#:~:text=The%20number%20of%20voting%20representatives,of%20the%20Northern%20Mariana%20Islands.). The number of representatives a state has is proportional to their population. As of the 2022 election, California is the most represented state with 52 representatives, while states like Alaska, Delaware, Vermont, and both of the Dakotas, each have only 1 representative. These numbers are always subject to change, for example, in the 2020 election California had 53 representatives. Below we’ll look at the net gain/loss for each state from 1976 through 2022, with a bit of focus on my home state of New York.\n\n\nCode\n# House overtime\nhouse_grouped &lt;- house |&gt;\n  group_by(state, year) |&gt;\n  summarize(\n    seats = n_distinct(district),\n    .groups = 'drop'\n  )\n\n# Have to manually input for DC\nhouse_grouped &lt;- house_grouped |&gt;\n  bind_rows(\n    data.frame(state = \"DISTRICT OF COLUMBIA\", year = 1976, seats = 0),\n    data.frame(state = \"DISTRICT OF COLUMBIA\", year = 2022, seats = 1) # See footnote\n  )\n\n# Electoral Votes change from 1976 to 2022\nhouse_overtime &lt;- house_grouped |&gt;\n  group_by(state) |&gt;\n  mutate(votes_change = seats[year == 2022] - seats[year == 1976],\n         .groups = 'drop'\n         ) |&gt;\n  filter(year == 2022) |&gt;\n  select(state,seats, votes_change)\n\n# Identify the top 3 increases and decreases\ntop_increase &lt;- house_overtime |&gt;\n  ungroup() |&gt;\n  slice_max(order_by = votes_change, n=3)\n\ntop_decrease &lt;- house_overtime |&gt;\n  ungroup() |&gt;\n  arrange(votes_change) |&gt;\n  slice_head(n=3)\n\n# Add a 'highlight' column to label the states for plotting\nstate_changes &lt;- house_overtime |&gt;\n  mutate(\n    highlight = case_when(\n      state %in% top_increase$state ~ \"increase\",\n      state %in% top_decrease$state ~ \"decrease\",\n      TRUE ~ \"normal\"\n    )\n  )\n\n# Barplot of changes overtime\nggplot(state_changes, aes(x = reorder(state, votes_change), y = votes_change, fill = votes_change)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_gradient2(\n    low = \"red\",\n    mid = \"gray\",\n    high = \"green\",\n    midpoint = 0,   # Center the color scale\n    guide = \"none\"  # Removes the legend\n  ) +\n  labs(\n    x = \"State\",\n    y = \"House Seats Change\",\n    title = \"Change in House Seats from 1976 to 2022 by State\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nDC is counted as having a representative according to this dataset. According to DC’s website:\n\nNational Level Representation\n\n\nDC residents elect a non-voting delegate to the US House of Representatives, two shadow Senators, and one shadow Representative whose task is to petition Congress for statehood.\n\nSimilarly, how many Electoral Votes have been gained/lost in that timespan?\n\n\nCode\n# Create table of electoral votes for later\nevotes &lt;- house |&gt;\n  group_by(state, year) |&gt;\n  summarize(\n    electoral_votes = n_distinct(district) + 2, # Num districts + 2\n    .groups = 'drop'\n  )\n\n# Have to manually input for DC\nevotes &lt;- evotes |&gt;\n  bind_rows(\n    data.frame(state = \"DISTRICT OF COLUMBIA\", year = 1976, electoral_votes = 3),\n    data.frame(state = \"DISTRICT OF COLUMBIA\", year = 2022, electoral_votes = 3)\n  )\n\n#| code-fold: TRUE\n# Electoral Votes change from 1976 to 2022\nevotes_overtime &lt;- evotes |&gt;\n  group_by(state) |&gt;\n  mutate(votes_change = electoral_votes[year == 2022] - electoral_votes[year == 1976],\n         .groups = 'drop'\n         ) |&gt;\n  filter(year == 2022) |&gt;\n  select(state,electoral_votes, votes_change)\n\n# Identify the top 3 increases and decreases\ntop_increase &lt;- evotes_overtime |&gt;\n  ungroup() |&gt;\n  slice_max(order_by = votes_change, n=3)\n\ntop_decrease &lt;- evotes_overtime |&gt;\n  ungroup() |&gt;\n  arrange(votes_change) |&gt;\n  slice_head(n=3)\n\n# Add a 'highlight' column to label the states for plotting\nstate_changes &lt;- evotes_overtime |&gt;\n  mutate(\n    highlight = case_when(\n      state %in% top_increase$state ~ \"increase\",\n      state %in% top_decrease$state ~ \"decrease\",\n      TRUE ~ \"normal\"\n    )\n  )\n\n# Barplot of changes overtime\nggplot(state_changes, aes(x = reorder(state, votes_change), y = votes_change, fill = votes_change)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_gradient2(\n    low = \"red\",\n    mid = \"gray\",\n    high = \"green\",\n    midpoint = 0,   # Center the color scale\n    guide = \"none\"  # Removes the legend\n  ) +\n  labs(\n    x = \"State\",\n    y = \"Electoral Votes Change\",\n    title = \"Change in Electoral College Votes from 1976 to 2022 by State\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nTaking a quick look at New York’s Electoral Votes over time for New York.\n\n# View New York's electoral votes over the decades\nevotes |&gt;\n  filter(state == \"NEW YORK\", year %in% c(1980, 2000, 2020))\n\n# A tibble: 3 × 3\n  state     year electoral_votes\n  &lt;chr&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n1 NEW YORK  1980              41\n2 NEW YORK  2000              33\n3 NEW YORK  2020              29\n\n\nAnd finally, a line graph of all 50 States’ Electoral Votes + DC\n\n\nCode\n# Create the line graph with ggplot2\nline_graph &lt;- ggplot(evotes, aes(x = year, y = electoral_votes, group = state, color = state)) +\n  geom_line() +\n  geom_point() +\n  scale_color_viridis_d() +\n  labs(\n    x = \"Year\",\n    y = \"Electoral Votes\",\n    title = \"Electoral Votes by State from 1976 to 2012 (Interactive)\",\n    subtitle = \"Line Graph of Electoral Votes Over Time\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1),\n    legend.position = \"none\"\n  )\n\n# Convert the ggplot2 plot to a plotly plot for interactivity\ninteractive_plot &lt;- ggplotly(line_graph)\n\n# Display the interactive plot\ninteractive_plot\n\n\n\n\n\n\nA bit of a busy linegraph because there’s 50 States + DC on it, but some interesting trends on it."
  },
  {
    "objectID": "mp03.html#task-3.2-fusion",
    "href": "mp03.html#task-3.2-fusion",
    "title": "Mini Project 3",
    "section": "TASK 3.2: Fusion",
    "text": "TASK 3.2: Fusion\n\nNew York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).\n\n\nAre there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\n\nTo answer this question, let’s first find the election mentioned above, then group votes on both party and candidate separately to see if we can find any outstanding differences between the two in any election.\nLet’s group our house table on Candidate and Party.\n\n\nCode\n# Let's find this instance\nhouse |&gt;\n  filter(year==2022, state==\"NEW YORK\", district==12) |&gt;\n  mutate(candidate = str_to_lower(candidate),\n         candidate = toTitleCase(candidate)) |&gt;\n  group_by(candidate) |&gt;\n  summarize(votes = sum(candidatevotes)) |&gt;\n  arrange(desc(votes))  |&gt;\n  DT::datatable(\n    colnames = c(\"Candidate\", \"Votes\"),\n    options = list(\n      pageLength = 7,\n      columnDefs = list(\n        list(\n          targets = c(2),\n          render = JS(\n            \"function(data, type, row, meta) {\",\n            \"  return type === 'display' ? data.toString().replace(/\\\\B(?=(\\\\d{3})+(?!\\\\d))/g, ',') : data;\",\n            \"}\"\n          )\n        ))))\n\n\n\n\n\n\nCode\n# Summarize the votes by Party rather than by Candidate\nhouse |&gt;\n  filter(year == 2022, state == \"NEW YORK\", district == 12) |&gt;\n  mutate(party = tidyr::replace_na(party, \"Blank/Write-In\"),\n         party = str_to_lower(party),\n         party = toTitleCase(party)) |&gt;\n  group_by(party) |&gt;\n  summarize(votes = sum(candidatevotes)) |&gt;\n  arrange(desc(votes)) |&gt;\n  DT::datatable(\n    colnames = c(\"Party\", \"Votes\"),\n    options = list(\n      pageLength = 7,\n      columnDefs = list(\n        list(\n          targets = c(2),\n          render = JS(\n            \"function(data, type, row, meta) {\",\n            \"  return type === 'display' ? data.toString().replace(/\\\\B(?=(\\\\d{3})+(?!\\\\d))/g, ',') : data;\",\n            \"}\"\n          )\n        ))))\n\n\n\n\n\n\nThis is the sample from the prompt, both grouped by candidate name and their associated party(s).\nLet’s answer this question by combining these two groupings.\nThe collapsed code below looked for instances where:\n\nThe candidate who won got some vote percentage between 30% and 70% of total votes (so it’s in a reasonable “flippable” range)\nThe candidate who won appeared on the ballot more than once\nNo party received more than 50% of the vote (If they did, then this question is moot)\n\n\n\nCode\n# First let's find races that were really close. Let's do this by defining a \"% of total vote column\"\n# Create pctvote_party and pctvote_candidate columns\nhouse &lt;- house |&gt;\n  # For pctvote_party, group by year, state, and party\n  group_by(year, state, district, party) |&gt;\n  mutate(pctvote_party = candidatevotes / totalvotes) |&gt;\n  # For pctvote_candidate, group by year, state, and candidate\n  group_by(year, state, district, candidate) |&gt;\n  mutate(pctvote_candidate = sum(candidatevotes) / totalvotes) |&gt;\n  # Ungroup to finish\n  ungroup() |&gt;\n  add_count(year, state, district, candidate, name = \"ballotcount\")\n\n# Let's find the most instances of multiple ballots\nhouse_votes &lt;- house |&gt; # Start with just the cols we want\n  select(year, state, district, stage,\n         candidate, ballotcount,party,\n         candidatevotes,totalvotes,\n         pctvote_party, pctvote_candidate\n         ) |&gt; \n  group_by(year, state, candidate) |&gt; # return anything where the percentage vote for the candidate fell into a reasonable range where it could be overturned\n  filter(all(pctvote_candidate &gt; 0.3), all(pctvote_candidate &lt; 0.7)) |&gt; \n  ungroup() |&gt;\n  group_by(year, state, district) |&gt;\n  filter(any(ballotcount &gt;= 2),\n         all(pctvote_party &lt;= 0.5), # If any of the party votes have over 50%, it won't matter what the rest are\n         all(pctvote_candidate &gt; 0.3), all(pctvote_candidate &lt; 0.7)) |&gt;  \n  ungroup() |&gt;\n  filter(n_distinct(c(year, state, district)) &gt; 1) |&gt;\n  group_by(year, state, district) |&gt;\n  mutate(max_pctvote_candidate = pctvote_candidate == max(pctvote_candidate)) |&gt;\n  ungroup() |&gt;\n  group_by(year, state, district) |&gt;\n  mutate(max_pctvote_party = pctvote_party == max(pctvote_party)) |&gt;\n  ungroup() |&gt;\n  mutate(max_pctvote_candidate = ifelse(max_pctvote_candidate, 1, 0),\n         max_pctvote_party = ifelse(max_pctvote_party, 1, 0))\n\nhouse_votes |&gt;\n  filter(year == 2000, state == \"CONNECTICUT\", district == 2) |&gt;\n  select(year, state, district, candidate, party, ballotcount, candidatevotes, pctvote_candidate, pctvote_party, max_pctvote_party, max_pctvote_candidate) |&gt;\n  mutate(state = str_to_lower(state),\n         state = toTitleCase(state),\n         candidate = str_to_lower(candidate),\n         candidate = toTitleCase(candidate),\n         party = str_to_lower(party),\n         party = toTitleCase(party)) |&gt;\n  rename_with(~ str_to_title(.x)) |&gt;\n  rename(\"Party Received Highest % Votes in Election\" = `Max_pctvote_party`,\n         \"Candidate Received Highest % Votes in Election\" = `Max_pctvote_candidate`,\n         \"Candidate's % Votes in Election\" = `Pctvote_candidate`,\n         \"Party's % Vote in Election\" = `Pctvote_party`,\n         \"Number of Times Candidate Appears on Ballot\" = `Ballotcount`,\n         \"Candidate Votes\" = `Candidatevotes`) |&gt;\n  DT::datatable(options = list(pageLength = 3,\n                   columnDefs = list(\n                     # Adding commas for these columns\n                     list(\n                       targets = c(7),\n                       render = JS(\n                         \"function(data, type, row, meta) {\",\n                         \"  return type === 'display' ? data.toString().replace(/\\\\B(?=(\\\\d{3})+(?!\\\\d))/g, ',') : data;\",  # Adding commas\n                         \"}\"\n                       )\n                     ),\n                     # Formatting as percentages for columns 6, 9, and 10\n                     list(\n                       targets = c(8,9),\n                       render = JS(\n                         \"function(data, type, row, meta) {\",\n                         \"  return type === 'display' ? (data * 100).toFixed(2) + '%' : data;\",  # Formatting as percentage\n                         \"}\"\n                       )\n                     )\n                   )\n    )\n  )\n\n\n\n\n\n\nIn Connecticut’s 2nd District in 2000, Sam Gejdenson’s Democratic party received the most votes, however candidate Rob Simmons on the Independent and Republican ticket won the vote by a razor-thin margin that required votes from both parties"
  },
  {
    "objectID": "mp03.html#task-3.3-follow-you-follow-me",
    "href": "mp03.html#task-3.3-follow-you-follow-me",
    "title": "Mini Project 3",
    "section": "TASK 3.3: Follow You Follow Me",
    "text": "TASK 3.3: Follow You Follow Me\n\nDo presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?\n\n\nDoes this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\nLooking at the percentage of votes won across the districts in both the Congressional and Presidential races should tell us the answer to this.\n\n\nCode\n# Let's change up the presidents table\n# First grouping all of the parties by state, year, and district\n# using `party_simplified`\npresidents_states &lt;- presidents |&gt;\n  group_by(year, state, party_simplified) |&gt;\n  summarize(partyvotes = sum(candidatevotes)) |&gt;\n  ungroup() |&gt;\n  group_by(year, state) |&gt;\n  mutate(totalvotes = sum(partyvotes)) |&gt;\n  ungroup() |&gt;\n  mutate(pctvotes = if_else(is.na(partyvotes), 0, partyvotes / totalvotes))\n\n# Creating a `party_simplified` column\nparty_dict &lt;- presidents |&gt;\n  distinct(party_simplified, party_detailed) |&gt;\n  deframe() # This converts the two columns into a named vector\n\nhouse &lt;- house |&gt;\n  mutate(\n    party_simplified = case_when(\n      party %in% names(party_dict) ~ party,  # If the party matches one in the dictionary\n      is.na(party) ~ \"OTHER\",               # If the party is NA\n      TRUE ~ \"OTHER\"                        # If the party is not found in the dictionary\n    )) \n\n# Create the same grouped df as for presidents\nhouse_states &lt;- house |&gt;\n  group_by(year, state, party_simplified) |&gt;\n  summarize(partyvotes = sum(candidatevotes)) |&gt;\n  ungroup() |&gt;\n  group_by(year, state) |&gt;\n  mutate(totalvotes = sum(partyvotes)) |&gt;\n  ungroup() |&gt;\n  mutate(pctvotes = if_else(is.na(partyvotes), 0, partyvotes / totalvotes))\n\n# Merge the two state pct dfs\nmerged_states &lt;- presidents_states |&gt;\n  left_join(house_states, by = c(\"year\", \"state\", \"party_simplified\"), suffix = c(\"_president\", \"_house\")) |&gt;\n  mutate(across(ends_with(\"_house\"), ~coalesce(.x, 0))) |&gt; # Replace NAs in columns ending with _house with 0\n  filter(party_simplified %in% c(\"DEMOCRAT\",\"REPUBLICAN\")) |&gt; # Yes we could look at libertarian and other, but it seems a bit overkill for this\n  rename(`party` = `party_simplified`) |&gt;\n  mutate(pctdiff = abs(pctvotes_president - pctvotes_house)) |&gt;\n  mutate(\n    pctdiff = abs(pctvotes_president - pctvotes_house),  # Create percentage difference column\n    pctdiff_cat = case_when(                             \n      pctdiff &lt; 0.35 ~ \"Low\",\n      pctdiff &gt;= 0.35 & pctdiff &lt;= 0.65 ~ \"Medium\",\n      pctdiff &gt; 0.65 ~ \"High\"\n    )\n  ) |&gt;\n  filter(partyvotes_house &gt; 1, partyvotes_president &gt; 1) |&gt;\n  mutate(pctvotes_president = round(pctvotes_president,4),\n         pctvotes_house = round(pctvotes_house, 4),\n         pctdiff = round(pctdiff, 4))\n\nsummarized_data &lt;- merged_states |&gt;\n  group_by(pctdiff_cat) |&gt;\n  summarize(n = n())  # Summarizing the counts for each category\n\n# Create the bar plot\nggplot(summarized_data, aes(x = pctdiff_cat, y = n, fill = pctdiff_cat)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  labs(\n    title = \"Distribution of Percentage Difference\",\n    x = \"Percentage Difference of Presidential vs Representative Votes\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.background = element_rect(fill = \"gray\", color = NA),\n    panel.background = element_rect(fill = \"gray\", color = NA), \n    legend.background = element_rect(fill = \"gray\", color = NA),\n    plot.title = element_text(hjust = 0.5)                      \n  ) +\n  scale_fill_manual(values = c(\"Low\" = \"darkgreen\", \"Medium\" = \"darkblue\", \"High\" = \"darkred\"))\n\n\n\n\n\n\n\n\n\nCode\n# These are the instances where there was a noticeable difference\nmerged_states |&gt;\n  filter(pctdiff_cat %in% c(\"Medium\",\"High\")) |&gt;\n  arrange(desc(pctdiff)) |&gt;\n  mutate(year = str_to_lower(year),\n         year = toTitleCase(year),\n         state = str_to_lower(state),\n         state = toTitleCase(state),\n         party = str_to_lower(party),\n         party = toTitleCase(party)) |&gt;\n  rename_with(~ str_to_title(.x)) |&gt;\n  rename(\n    \"Party's Votes in State & Year for Presidential Election\" = `Partyvotes_president`,\n    \"Total Votes in State & Year for Presidential Election\" = `Totalvotes_president`,\n    \"Votes % in State & Year for Party in Presidential Election\" = `Pctvotes_president`,\n    \"Party's Votes in State & Year for Congressional Election\" = `Partyvotes_house`,\n    \"Total Votes in State & Year for Congressional Election\" = `Totalvotes_house`,\n    \"Votes % in State & Year for Party in Congressional Election\" = `Pctvotes_house`,\n    \"Percentage Difference in State & Year between Presidential and House Votes\" = `Pctdiff`,\n    \"Category of Percentage Difference in State & Year between Presidential and House Votes\" = `Pctdiff_cat`\n  ) |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = 18,\n      columnDefs = list(\n        # Adding commas for these columns\n        list(\n          targets = c(4, 5, 7, 8),\n          render = JS(\n            \"function(data, type, row, meta) {\",\n            \"  return type === 'display' ? data.toString().replace(/\\\\B(?=(\\\\d{3})+(?!\\\\d))/g, ',') : data;\",  # Adding commas\n            \"}\"\n          )\n        ),\n        # Formatting as percentages for columns 6, 9, and 10\n        list(\n          targets = c(6, 9, 10),\n          render = JS(\n            \"function(data, type, row, meta) {\",\n            \"  return type === 'display' ? (data * 100).toFixed(2) + '%' : data;\",  # Formatting as percentage\n            \"}\"\n          )\n        )\n      )\n    )\n  )\n\n\n\n\n\n\nCode\n# Diff by party\nmerged_states |&gt;\n  filter(pctdiff_cat == \"Medium\") |&gt;\n  group_by(party) |&gt;\n  summarize(n())\n\n\n# A tibble: 2 × 2\n  party      `n()`\n  &lt;chr&gt;      &lt;int&gt;\n1 DEMOCRAT      11\n2 REPUBLICAN     7\n\n\nCode\n# Diff by states\nmerged_states |&gt;\n  filter(pctdiff_cat == \"Medium\") |&gt;\n  group_by(state) |&gt;\n  summarize(count = n()) |&gt;\n  arrange(desc(count))\n\n\n# A tibble: 7 × 2\n  state         count\n  &lt;chr&gt;         &lt;int&gt;\n1 HAWAII            4\n2 VERMONT           4\n3 NEVADA            3\n4 ARKANSAS          2\n5 LOUISIANA         2\n6 NORTH DAKOTA      2\n7 WEST VIRGINIA     1\n\n\nWe see that, although it has somewhat happened, a district will usually vote the same along party-lines for any given election, with few exceptions.\nOf the 1,189 District + Year combinations in the dataset that voted in both a Congressional race and Presidential race in the same year, 1,171 followed party-lines (had a deviation in total % of vote of less than 35%), while 18 were in a range of 35 - 65%, and none deviated above 65%."
  },
  {
    "objectID": "mp04.html",
    "href": "mp04.html",
    "title": "Mini Project 4",
    "section": "",
    "text": "CUNY Retirement Plans\n\nIntroduction\nMore to come soon on MP 04."
  }
]